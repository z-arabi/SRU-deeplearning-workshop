{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
    "\n",
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">مقدمه‌ای بر شبکه‌های عصبی و چارچوب Keras (کراس)</div></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">لود کتابخانه‌های مورد استفاده</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "\n",
    "برای اجرای این نوت‌بوک نیاز به نصب کتابخانه کراس (Keras) دارید. برای نصب این کتابخانه میتوانید لینک زیر را مطالعه کنید.\n",
    "</div>\n",
    "\n",
    "[http://blog.class.vision/1396/12/installing-keras-with-tensorflow-backend/](http://blog.class.vision/1396/12/installing-keras-with-tensorflow-backend/)\n",
    "\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "در صورتی که تمام کتابخانه‌های مورد نیاز شما نصب باشد سلول زیر باید بدون مشکل اجرا شود.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "de829a92-1fb6-44ad-a2c6-fc1001e1f6e1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,  Activation\n",
    "import numpy as np\n",
    "\n",
    "from dataset import load_hoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://colab.class.vision/dataset/Data_hoda_full.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more information read \"19-Intro2ML-HodaDataset.ipynb\"\n",
    "import cv2\n",
    "from scipy import io\n",
    "\n",
    "def load_hoda(training_sample_size=1000, test_sample_size=200, size=5):\n",
    "    #load dataset\n",
    "    trs = training_sample_size\n",
    "    tes = test_sample_size\n",
    "    dataset = io.loadmat('./Data_hoda_full.mat')\n",
    "\n",
    "    #test and training set\n",
    "    X_train_orginal = np.squeeze(dataset['Data'][:trs])\n",
    "    y_train = np.squeeze(dataset['labels'][:trs])\n",
    "    X_test_original = np.squeeze(dataset['Data'][trs:trs+tes])\n",
    "    y_test = np.squeeze(dataset['labels'][trs:trs+tes])\n",
    "\n",
    "    #resize\n",
    "    X_train_5by5 = [cv2.resize(img, dsize=(size, size)) for img in X_train_orginal]\n",
    "    X_test_5by_5 = [cv2.resize(img, dsize=(size, size)) for img in X_test_original]\n",
    "    #reshape\n",
    "    X_train = [x.reshape(size*size) for x in X_train_5by5]\n",
    "    X_test = [x.reshape(size*size) for x in X_test_5by_5]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "برای اینکه موقع اجرای کدها دقیقا نتایج سر کلاس را بتوانید مشاهده کنید\n",
    ":\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">لود مجموعه داده (dataset)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> پیش‌پردازش داده‌ها برای Keras</div>\n",
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "تبدیل\n",
    "x_train و x_test\n",
    "به فرمت آرایه‌های نامپای یا ndarray و تبدیل \n",
    "y_train و y_test\n",
    "به \n",
    "one-hot-encoding\n",
    ":\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "ابتدا تابعی ساده تعریف کردهایم که ابعاد، نوع داده ای و اطلاعات دیتاست لود شده را چاپ کند.\n",
    "<br>\n",
    "این اطلاعات را قبل و بعد از پیش‌پردازش داده ها چاپ خواهیم کرد تا متوجه تغییرات بشویم!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(x_train, y_train, x_test, y_test):\n",
    "    #Check data Type\n",
    "    print (\"\\ttype(x_train): {}\".format(type(x_train)))\n",
    "    print (\"\\ttype(y_train): {}\".format(type(y_train)))\n",
    "\n",
    "    #check data Shape\n",
    "    print (\"\\tx_train.shape: {}\".format(np.shape(x_train)))\n",
    "    print (\"\\ty_train.shape: {}\".format(np.shape(y_train)))\n",
    "    print (\"\\tx_test.shape: {}\".format(np.shape(x_test)))\n",
    "    print (\"\\ty_test.shape: {}\".format(np.shape(y_test)))\n",
    "\n",
    "    #sample data\n",
    "    print (\"\\ty_train[0]: {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data for Keras. \n",
    "x_train = np.array(x_train_original)\n",
    "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
    "x_test = np.array(x_test_original)\n",
    "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Preprocessing:\n",
      "\ttype(x_train): <class 'list'>\n",
      "\ttype(y_train): <class 'numpy.ndarray'>\n",
      "\tx_train.shape: (1000, 25)\n",
      "\ty_train.shape: (1000,)\n",
      "\tx_test.shape: (200, 25)\n",
      "\ty_test.shape: (200,)\n",
      "\ty_train[0]: 6\n",
      "After Preprocessing:\n",
      "\ttype(x_train): <class 'numpy.ndarray'>\n",
      "\ttype(y_train): <class 'numpy.ndarray'>\n",
      "\tx_train.shape: (1000, 25)\n",
      "\ty_train.shape: (1000, 10)\n",
      "\tx_test.shape: (200, 25)\n",
      "\ty_test.shape: (200, 10)\n",
      "\ty_train[0]: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Preprocessing:\")\n",
    "print_data_info(x_train_original, y_train_original, x_test_original, y_test_original)\n",
    "print(\"After Preprocessing:\")\n",
    "print_data_info(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "آخرین گام پیش‌پردازش تبدیل داده‌ها به \n",
    "**float32**\n",
    "و نرمال سازی مقادیر به مقدار بین 0 و 1 است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">تعریف معماری مدل (model architecture)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=25))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 64)                1664      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 2,314\n",
      "Trainable params: 2,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">Compile model</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">آموش مدل با داده‌های آموزشی</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 2.1480 - acc: 0.2213 - val_loss: 2.0126 - val_acc: 0.3600\n",
      "Epoch 2/30\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.9575 - acc: 0.3725 - val_loss: 1.8539 - val_acc: 0.5150\n",
      "Epoch 3/30\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.7997 - acc: 0.4987 - val_loss: 1.7062 - val_acc: 0.6100\n",
      "Epoch 4/30\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6491 - acc: 0.6013 - val_loss: 1.5655 - val_acc: 0.6400\n",
      "Epoch 5/30\n",
      "800/800 [==============================] - 0s 91us/step - loss: 1.5039 - acc: 0.6512 - val_loss: 1.4288 - val_acc: 0.6800\n",
      "Epoch 6/30\n",
      "800/800 [==============================] - 0s 77us/step - loss: 1.3661 - acc: 0.6938 - val_loss: 1.3076 - val_acc: 0.7200\n",
      "Epoch 7/30\n",
      "800/800 [==============================] - 0s 80us/step - loss: 1.2389 - acc: 0.7563 - val_loss: 1.1904 - val_acc: 0.7200\n",
      "Epoch 8/30\n",
      "800/800 [==============================] - 0s 90us/step - loss: 1.1225 - acc: 0.7850 - val_loss: 1.0848 - val_acc: 0.7600\n",
      "Epoch 9/30\n",
      "800/800 [==============================] - 0s 86us/step - loss: 1.0188 - acc: 0.7913 - val_loss: 0.9926 - val_acc: 0.7950\n",
      "Epoch 10/30\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.9268 - acc: 0.8113 - val_loss: 0.9109 - val_acc: 0.8100\n",
      "Epoch 11/30\n",
      "800/800 [==============================] - 0s 72us/step - loss: 0.8466 - acc: 0.8263 - val_loss: 0.8405 - val_acc: 0.8200\n",
      "Epoch 12/30\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.7775 - acc: 0.8300 - val_loss: 0.7799 - val_acc: 0.8150\n",
      "Epoch 13/30\n",
      "800/800 [==============================] - 0s 99us/step - loss: 0.7177 - acc: 0.8463 - val_loss: 0.7282 - val_acc: 0.8150\n",
      "Epoch 14/30\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.6662 - acc: 0.8525 - val_loss: 0.6833 - val_acc: 0.8150\n",
      "Epoch 15/30\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.6243 - acc: 0.8550 - val_loss: 0.6532 - val_acc: 0.8300\n",
      "Epoch 16/30\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.5884 - acc: 0.8638 - val_loss: 0.6199 - val_acc: 0.8350\n",
      "Epoch 17/30\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.5549 - acc: 0.8700 - val_loss: 0.5930 - val_acc: 0.8350\n",
      "Epoch 18/30\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.5263 - acc: 0.8712 - val_loss: 0.5654 - val_acc: 0.8400\n",
      "Epoch 19/30\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.4993 - acc: 0.8738 - val_loss: 0.5436 - val_acc: 0.8350\n",
      "Epoch 20/30\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.4757 - acc: 0.8800 - val_loss: 0.5245 - val_acc: 0.8400\n",
      "Epoch 21/30\n",
      "800/800 [==============================] - 0s 102us/step - loss: 0.4557 - acc: 0.8750 - val_loss: 0.5110 - val_acc: 0.8450\n",
      "Epoch 22/30\n",
      "800/800 [==============================] - 0s 102us/step - loss: 0.4376 - acc: 0.8837 - val_loss: 0.4938 - val_acc: 0.8450\n",
      "Epoch 23/30\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.4199 - acc: 0.8862 - val_loss: 0.4797 - val_acc: 0.8600\n",
      "Epoch 24/30\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.4053 - acc: 0.8912 - val_loss: 0.4668 - val_acc: 0.8650\n",
      "Epoch 25/30\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3912 - acc: 0.8888 - val_loss: 0.4570 - val_acc: 0.8750\n",
      "Epoch 26/30\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.3807 - acc: 0.8900 - val_loss: 0.4476 - val_acc: 0.8750\n",
      "Epoch 27/30\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.3672 - acc: 0.8975 - val_loss: 0.4401 - val_acc: 0.8750\n",
      "Epoch 28/30\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3564 - acc: 0.9000 - val_loss: 0.4295 - val_acc: 0.8700\n",
      "Epoch 29/30\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.3468 - acc: 0.8975 - val_loss: 0.4284 - val_acc: 0.8700\n",
      "Epoch 30/30\n",
      "800/800 [==============================] - 0s 87us/step - loss: 0.3369 - acc: 0.8987 - val_loss: 0.4149 - val_acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b50473f28>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=30,\n",
    "          batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">ارزیابی مدل روی داده های آزمون</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 75us/step\n",
      "\n",
      "Testing loss: 0.36, acc: 0.91%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('\\nTesting loss: %.2f, acc: %.2f%%'%(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">پیش‌بینی داده‌های آموزشی</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:\n",
      "[7 2 3 8 5 5 4 7 3 2 0 8 8 0 2 9 3 6 7 4 0 3 6 3 9 2 7 5 2 9 7 5 5 8 9 2 5\n",
      " 1 4 8 8 4 7 2 1 2 7 9 0 3 7 5 7 5 7 9 8 2 9 8 8 6 6 6 7 6 2 4 2 4 1 5 9 1\n",
      " 8 4 0 5 6 2 4 3 2 7 7 7 7 0 8 1 7 8 7 7 8 9 6 2 3 1 0 2 9 6 3 5 5 0 0 9 6\n",
      " 7 9 3 9 9 8 7 9 2 5 2 5 5 9 6 9 2 0 3 7 9 5 2 9 0 4 1 8 2 2 3 5 2 9 3 8 2\n",
      " 7 0 9 9 0 7 6 2 4 7 9 3 7 0 7 1 9 4 7 3 4 1 5 6 7 9 1 3 5 3 5 7 4 1 3 3 1\n",
      " 1 4 3 8 9 6 7 7 2 3 0 1 4 9 5]\n",
      "True Label:\n",
      "[7 2 3 1 5 5 4 7 3 2 0 8 8 0 2 9 3 6 7 4 0 3 6 3 9 2 7 5 2 9 7 5 5 8 9 6 5\n",
      " 1 4 8 8 4 7 7 1 2 7 9 0 3 7 4 7 5 2 9 8 2 9 8 8 6 6 6 6 6 2 4 3 4 4 5 9 1\n",
      " 8 2 0 5 6 2 4 3 2 7 7 7 7 1 8 1 7 8 7 7 8 9 3 2 3 1 0 2 9 6 3 5 5 0 0 3 6\n",
      " 7 9 3 9 9 8 7 9 2 5 2 5 5 9 6 9 2 0 3 7 6 5 2 9 0 4 1 8 2 2 3 0 2 9 3 8 6\n",
      " 7 0 9 9 0 7 6 5 4 7 9 3 7 0 7 1 9 4 7 3 4 1 5 6 7 9 1 3 5 4 5 7 4 1 3 3 1\n",
      " 2 3 3 8 9 6 7 7 2 3 0 1 4 9 5]\n"
     ]
    }
   ],
   "source": [
    "# The predict_classes function outputs the highest probability class\n",
    "# according to the trained classifier for each input example.\n",
    "predicted_classes = model.predict_classes(x_test)\n",
    "print(\"predicted:\")\n",
    "print(predicted_classes)\n",
    "print(\"True Label:\")\n",
    "print(y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">کد کامل، از ابتدا تا انتها</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import libraries and modules\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "from dataset import load_hoda\n",
    "\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "# 2. Load pre-shuffled HODA data into train and test sets\n",
    "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda()\n",
    "\n",
    "# 3. Preprocess input data\n",
    "''' 3.1: input data in numpy array format'''\n",
    "x_train = np.array(x_train_original)\n",
    "x_test = np.array(x_test_original)\n",
    "'''3.2 normalize our data values to the range [0, 1]'''\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# 4. Preprocess class labels\n",
    "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n",
    "\n",
    "# 5. Define model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 6. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 7. Fit model on training data\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=30,\n",
    "          batch_size=64)\n",
    "\n",
    "# 8. Evaluate model on test data\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('\\nTesting loss: %.2f, acc: %.2f%%'%(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> دوره مقدماتی یادگیری عمیق<br>علیرضا اخوان پور<br><br>\n",
    "</div>\n",
    "<a href=\"http://class.vision\">Class.Vision</a> - <a href=\"http://AkhavanPour.ir\">AkhavanPour.ir</a> - <a href=\"https://github.com/Alireza-Akhavan/\">GitHub</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbpresent": {
   "slides": {
    "300ee14f-a043-486e-b274-7ff253907cd7": {
     "id": "300ee14f-a043-486e-b274-7ff253907cd7",
     "prev": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "regions": {
      "26dc3f39-a230-447c-af4c-f5e5b2fb7835": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c58440a5-3f8f-4f37-9c79-6bf766209406",
        "part": "whole"
       },
       "id": "26dc3f39-a230-447c-af4c-f5e5b2fb7835"
      }
     }
    },
    "878aa53a-1444-4100-8f50-7a408191c579": {
     "id": "878aa53a-1444-4100-8f50-7a408191c579",
     "prev": null,
     "regions": {
      "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "588ee1fa-64b5-453b-ade7-8e6b2515821c",
        "part": "whole"
       },
       "id": "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3"
      }
     }
    },
    "96ffe88e-7b50-43de-afdd-942e564f4e3e": {
     "id": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "prev": "878aa53a-1444-4100-8f50-7a408191c579",
     "regions": {
      "b7e52e12-489a-468d-b10c-af2024fd2856": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de829a92-1fb6-44ad-a2c6-fc1001e1f6e1",
        "part": "whole"
       },
       "id": "b7e52e12-489a-468d-b10c-af2024fd2856"
      }
     }
    },
    "cb74e0bc-4513-4d13-b7f1-14c3078a7927": {
     "id": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "prev": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "regions": {
      "444878ee-68f3-4abb-acff-a7079b21e86d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "25f3f538-1ee8-4d98-a6bb-14cbeb7a702d",
        "part": "whole"
       },
       "id": "444878ee-68f3-4abb-acff-a7079b21e86d"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

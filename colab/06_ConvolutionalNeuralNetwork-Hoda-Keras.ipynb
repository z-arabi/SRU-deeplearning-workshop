{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
    "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">مقدمه ای بر شبکه‌های عصبی کانولوشنالی<br>Convolutionl Neural Networks - CNN</div></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">مقدمه ای بر شبکه‌های عصبی کانولوشنالی(Convolutionl Neural Networks - CNN)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "در ابتدا معماری شبکه را مشخص میکنیم.\n",
    "<br>\n",
    "به لایه های conv و pool دقت کنید.\n",
    "<br>\n",
    "قبل از اولین لایه Dense یا Fully Connected همیشه متد Flatten فراخوانی میشود تا نورون ها به صورت یک وکتور در بیایند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">اجرا روی Colab</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "اگر روی گوگل کولب اجرا میکنید این خطوط را از حالت کامنت خارج نمائید.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
    "#!mkdir dataset\n",
    "#!wget https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat -P dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "from dataset import load_hoda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "نگاهی به تنسور وردی و خروجی هر لایه بیندازیم.\n",
    "<br>\n",
    "تصویر ورودی 28x28x3 بوده است\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">کد یک شبکه کانولوشنالی و آموزش آن از ابتدا تا انتها بر روی مجموعه داده هدی</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
    "تصاویر مجموعه داده هدی در تابعی که قبلا نوشته ایم، load_hoda به صورت flat شده و یک وکتور در آمده اند.\n",
    "<br>\n",
    "در این فراخوانی طول و عرض تصاویر 28 قرار داده شده است، پس خروجی این تابع وکتورهای 784تایی است.\n",
    "<br>\n",
    "** دقت کنید که قبل از ورودی شبکه کانولوشنالی تصویر را به شکل اصلی خود یعنی 28x28 برگردانده ایم.**\n",
    "<br>\n",
    "همچنین چون تصاویر سیاه و سفید است تعداد کانال تصویر را 1 قرار داده ایم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3500 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "3500/3500 [==============================] - 1s 358us/step - loss: 2.0753 - acc: 0.3260 - val_loss: 1.3986 - val_acc: 0.7250\n",
      "Epoch 2/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 1.2037 - acc: 0.5846 - val_loss: 0.5824 - val_acc: 0.8150\n",
      "Epoch 3/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.8154 - acc: 0.7123 - val_loss: 0.3902 - val_acc: 0.8550\n",
      "Epoch 4/200\n",
      "3500/3500 [==============================] - 1s 231us/step - loss: 0.6353 - acc: 0.7743 - val_loss: 0.2694 - val_acc: 0.9050\n",
      "Epoch 5/200\n",
      "3500/3500 [==============================] - 1s 175us/step - loss: 0.4933 - acc: 0.8286 - val_loss: 0.2339 - val_acc: 0.9100\n",
      "Epoch 6/200\n",
      "3500/3500 [==============================] - 1s 163us/step - loss: 0.4242 - acc: 0.8551 - val_loss: 0.2204 - val_acc: 0.9350\n",
      "Epoch 7/200\n",
      "3500/3500 [==============================] - 1s 167us/step - loss: 0.3744 - acc: 0.8740 - val_loss: 0.1964 - val_acc: 0.9350\n",
      "Epoch 8/200\n",
      "3500/3500 [==============================] - 0s 136us/step - loss: 0.3062 - acc: 0.8971 - val_loss: 0.1785 - val_acc: 0.9350\n",
      "Epoch 9/200\n",
      "3500/3500 [==============================] - 1s 159us/step - loss: 0.2947 - acc: 0.9046 - val_loss: 0.1695 - val_acc: 0.9350\n",
      "Epoch 10/200\n",
      "3500/3500 [==============================] - 0s 136us/step - loss: 0.2569 - acc: 0.9194 - val_loss: 0.1657 - val_acc: 0.9500\n",
      "Epoch 11/200\n",
      "3500/3500 [==============================] - 0s 119us/step - loss: 0.2376 - acc: 0.9231 - val_loss: 0.1531 - val_acc: 0.9500\n",
      "Epoch 12/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.2101 - acc: 0.9289 - val_loss: 0.1403 - val_acc: 0.9600\n",
      "Epoch 13/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.2005 - acc: 0.9337 - val_loss: 0.1290 - val_acc: 0.9600\n",
      "Epoch 14/200\n",
      "3500/3500 [==============================] - 0s 118us/step - loss: 0.2244 - acc: 0.9271 - val_loss: 0.1185 - val_acc: 0.9650\n",
      "Epoch 15/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.1925 - acc: 0.9403 - val_loss: 0.1215 - val_acc: 0.9650\n",
      "Epoch 16/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.1830 - acc: 0.9409 - val_loss: 0.1321 - val_acc: 0.9650\n",
      "Epoch 17/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.1564 - acc: 0.9486 - val_loss: 0.1129 - val_acc: 0.9650\n",
      "Epoch 18/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.1567 - acc: 0.9514 - val_loss: 0.1066 - val_acc: 0.9700\n",
      "Epoch 19/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.1437 - acc: 0.9543 - val_loss: 0.1178 - val_acc: 0.9600\n",
      "Epoch 20/200\n",
      "3500/3500 [==============================] - 1s 193us/step - loss: 0.1409 - acc: 0.9537 - val_loss: 0.1042 - val_acc: 0.9650\n",
      "Epoch 21/200\n",
      "3500/3500 [==============================] - 1s 155us/step - loss: 0.1368 - acc: 0.9566 - val_loss: 0.1029 - val_acc: 0.9600\n",
      "Epoch 22/200\n",
      "3500/3500 [==============================] - 1s 143us/step - loss: 0.1155 - acc: 0.9663 - val_loss: 0.1019 - val_acc: 0.9700\n",
      "Epoch 23/200\n",
      "3500/3500 [==============================] - 0s 133us/step - loss: 0.1226 - acc: 0.9586 - val_loss: 0.1234 - val_acc: 0.9750\n",
      "Epoch 24/200\n",
      "3500/3500 [==============================] - 0s 132us/step - loss: 0.1152 - acc: 0.9574 - val_loss: 0.1076 - val_acc: 0.9650\n",
      "Epoch 25/200\n",
      "3500/3500 [==============================] - 0s 134us/step - loss: 0.1018 - acc: 0.9666 - val_loss: 0.1147 - val_acc: 0.9750\n",
      "Epoch 26/200\n",
      "3500/3500 [==============================] - 0s 128us/step - loss: 0.1038 - acc: 0.9686 - val_loss: 0.1165 - val_acc: 0.9700\n",
      "Epoch 27/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0957 - acc: 0.9669 - val_loss: 0.1179 - val_acc: 0.9700\n",
      "Epoch 28/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0893 - acc: 0.9694 - val_loss: 0.1187 - val_acc: 0.9750\n",
      "Epoch 29/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0857 - acc: 0.9691 - val_loss: 0.1097 - val_acc: 0.9800\n",
      "Epoch 30/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0795 - acc: 0.9754 - val_loss: 0.1070 - val_acc: 0.9750\n",
      "Epoch 31/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0759 - acc: 0.9760 - val_loss: 0.0983 - val_acc: 0.9750\n",
      "Epoch 32/200\n",
      "3500/3500 [==============================] - 0s 117us/step - loss: 0.0830 - acc: 0.9709 - val_loss: 0.0969 - val_acc: 0.9850\n",
      "Epoch 33/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0787 - acc: 0.9714 - val_loss: 0.1184 - val_acc: 0.9700\n",
      "Epoch 34/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0804 - acc: 0.9720 - val_loss: 0.1285 - val_acc: 0.9750\n",
      "Epoch 35/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0815 - acc: 0.9706 - val_loss: 0.1288 - val_acc: 0.9800\n",
      "Epoch 36/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0698 - acc: 0.9763 - val_loss: 0.1085 - val_acc: 0.9750\n",
      "Epoch 37/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0665 - acc: 0.9771 - val_loss: 0.0895 - val_acc: 0.9800\n",
      "Epoch 38/200\n",
      "3500/3500 [==============================] - 0s 119us/step - loss: 0.0693 - acc: 0.9771 - val_loss: 0.1152 - val_acc: 0.9750\n",
      "Epoch 39/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0699 - acc: 0.9757 - val_loss: 0.1296 - val_acc: 0.9750\n",
      "Epoch 40/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0603 - acc: 0.9806 - val_loss: 0.1439 - val_acc: 0.9800\n",
      "Epoch 41/200\n",
      "3500/3500 [==============================] - 0s 119us/step - loss: 0.0616 - acc: 0.9786 - val_loss: 0.1343 - val_acc: 0.9750\n",
      "Epoch 42/200\n",
      "3500/3500 [==============================] - 0s 119us/step - loss: 0.0576 - acc: 0.9800 - val_loss: 0.1329 - val_acc: 0.9800\n",
      "Epoch 43/200\n",
      "3500/3500 [==============================] - 0s 119us/step - loss: 0.0504 - acc: 0.9811 - val_loss: 0.0930 - val_acc: 0.9850\n",
      "Epoch 44/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0455 - acc: 0.9829 - val_loss: 0.1175 - val_acc: 0.9800\n",
      "Epoch 45/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0473 - acc: 0.9846 - val_loss: 0.1063 - val_acc: 0.9850\n",
      "Epoch 46/200\n",
      "3500/3500 [==============================] - 0s 118us/step - loss: 0.0500 - acc: 0.9820 - val_loss: 0.0983 - val_acc: 0.9800\n",
      "Epoch 47/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0461 - acc: 0.9829 - val_loss: 0.1131 - val_acc: 0.9800\n",
      "Epoch 48/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0524 - acc: 0.9777 - val_loss: 0.1235 - val_acc: 0.9750\n",
      "Epoch 49/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0508 - acc: 0.9826 - val_loss: 0.1160 - val_acc: 0.9750\n",
      "Epoch 50/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0504 - acc: 0.9843 - val_loss: 0.1122 - val_acc: 0.9700\n",
      "Epoch 51/200\n",
      "3500/3500 [==============================] - 0s 119us/step - loss: 0.0445 - acc: 0.9854 - val_loss: 0.1422 - val_acc: 0.9750\n",
      "Epoch 52/200\n",
      "3500/3500 [==============================] - 0s 118us/step - loss: 0.0460 - acc: 0.9803 - val_loss: 0.0983 - val_acc: 0.9800\n",
      "Epoch 53/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0452 - acc: 0.9820 - val_loss: 0.1183 - val_acc: 0.9750\n",
      "Epoch 54/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0431 - acc: 0.9851 - val_loss: 0.1004 - val_acc: 0.9900\n",
      "Epoch 55/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0344 - acc: 0.9891 - val_loss: 0.1376 - val_acc: 0.9700\n",
      "Epoch 56/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0426 - acc: 0.9843 - val_loss: 0.1360 - val_acc: 0.9750\n",
      "Epoch 57/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0413 - acc: 0.9849 - val_loss: 0.1211 - val_acc: 0.9700\n",
      "Epoch 58/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0397 - acc: 0.9851 - val_loss: 0.1016 - val_acc: 0.9800\n",
      "Epoch 59/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0314 - acc: 0.9900 - val_loss: 0.1242 - val_acc: 0.9800\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0355 - acc: 0.9851 - val_loss: 0.1333 - val_acc: 0.9800\n",
      "Epoch 61/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0342 - acc: 0.9883 - val_loss: 0.1125 - val_acc: 0.9850\n",
      "Epoch 62/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0267 - acc: 0.9891 - val_loss: 0.1654 - val_acc: 0.9800\n",
      "Epoch 63/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0265 - acc: 0.9906 - val_loss: 0.0978 - val_acc: 0.9800\n",
      "Epoch 64/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0246 - acc: 0.9900 - val_loss: 0.1734 - val_acc: 0.9700\n",
      "Epoch 65/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0371 - acc: 0.9871 - val_loss: 0.1400 - val_acc: 0.9800\n",
      "Epoch 66/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0355 - acc: 0.9891 - val_loss: 0.1100 - val_acc: 0.9850\n",
      "Epoch 67/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0338 - acc: 0.9866 - val_loss: 0.1232 - val_acc: 0.9700\n",
      "Epoch 68/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0300 - acc: 0.9894 - val_loss: 0.1211 - val_acc: 0.9800\n",
      "Epoch 69/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0284 - acc: 0.9903 - val_loss: 0.1034 - val_acc: 0.9800\n",
      "Epoch 70/200\n",
      "3500/3500 [==============================] - 0s 127us/step - loss: 0.0400 - acc: 0.9869 - val_loss: 0.1226 - val_acc: 0.9800\n",
      "Epoch 71/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0348 - acc: 0.9869 - val_loss: 0.1385 - val_acc: 0.9750\n",
      "Epoch 72/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0333 - acc: 0.9869 - val_loss: 0.1099 - val_acc: 0.9850\n",
      "Epoch 73/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0324 - acc: 0.9886 - val_loss: 0.1174 - val_acc: 0.9850\n",
      "Epoch 74/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0288 - acc: 0.9900 - val_loss: 0.1725 - val_acc: 0.9800\n",
      "Epoch 75/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0197 - acc: 0.9934 - val_loss: 0.1549 - val_acc: 0.9800\n",
      "Epoch 76/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0275 - acc: 0.9894 - val_loss: 0.1217 - val_acc: 0.9750\n",
      "Epoch 77/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0287 - acc: 0.9877 - val_loss: 0.1105 - val_acc: 0.9800\n",
      "Epoch 78/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0264 - acc: 0.9906 - val_loss: 0.1320 - val_acc: 0.9800\n",
      "Epoch 79/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0279 - acc: 0.9894 - val_loss: 0.0662 - val_acc: 0.9900\n",
      "Epoch 80/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0241 - acc: 0.9920 - val_loss: 0.1212 - val_acc: 0.9800\n",
      "Epoch 81/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.1132 - val_acc: 0.9800\n",
      "Epoch 82/200\n",
      "3500/3500 [==============================] - 0s 118us/step - loss: 0.0251 - acc: 0.9911 - val_loss: 0.1423 - val_acc: 0.9800\n",
      "Epoch 83/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0244 - acc: 0.9917 - val_loss: 0.1216 - val_acc: 0.9750\n",
      "Epoch 84/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0258 - acc: 0.9914 - val_loss: 0.1610 - val_acc: 0.9800\n",
      "Epoch 85/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0238 - acc: 0.9923 - val_loss: 0.0945 - val_acc: 0.9850\n",
      "Epoch 86/200\n",
      "3500/3500 [==============================] - 0s 119us/step - loss: 0.0244 - acc: 0.9903 - val_loss: 0.0870 - val_acc: 0.9850\n",
      "Epoch 87/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0171 - acc: 0.9937 - val_loss: 0.1556 - val_acc: 0.9800\n",
      "Epoch 88/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.1073 - val_acc: 0.9800\n",
      "Epoch 89/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0177 - acc: 0.9940 - val_loss: 0.1171 - val_acc: 0.9850\n",
      "Epoch 90/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0216 - acc: 0.9931 - val_loss: 0.1612 - val_acc: 0.9800\n",
      "Epoch 91/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0241 - acc: 0.9914 - val_loss: 0.1747 - val_acc: 0.9700\n",
      "Epoch 92/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0161 - acc: 0.9949 - val_loss: 0.1530 - val_acc: 0.9800\n",
      "Epoch 93/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0249 - acc: 0.9914 - val_loss: 0.1463 - val_acc: 0.9800\n",
      "Epoch 94/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0216 - acc: 0.9914 - val_loss: 0.1304 - val_acc: 0.9750\n",
      "Epoch 95/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0242 - acc: 0.9931 - val_loss: 0.1448 - val_acc: 0.9800\n",
      "Epoch 96/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0240 - acc: 0.9920 - val_loss: 0.0894 - val_acc: 0.9900\n",
      "Epoch 97/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0232 - acc: 0.9920 - val_loss: 0.1269 - val_acc: 0.9800\n",
      "Epoch 98/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0210 - acc: 0.9917 - val_loss: 0.1371 - val_acc: 0.9800\n",
      "Epoch 99/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0205 - acc: 0.9931 - val_loss: 0.1492 - val_acc: 0.9800\n",
      "Epoch 100/200\n",
      "3500/3500 [==============================] - 0s 118us/step - loss: 0.0150 - acc: 0.9943 - val_loss: 0.1428 - val_acc: 0.9750\n",
      "Epoch 101/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0186 - acc: 0.9934 - val_loss: 0.1229 - val_acc: 0.9850\n",
      "Epoch 102/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0171 - acc: 0.9946 - val_loss: 0.1371 - val_acc: 0.9800\n",
      "Epoch 103/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0206 - acc: 0.9917 - val_loss: 0.1073 - val_acc: 0.9850\n",
      "Epoch 104/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0204 - acc: 0.9926 - val_loss: 0.1407 - val_acc: 0.9800\n",
      "Epoch 105/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0168 - acc: 0.9949 - val_loss: 0.1542 - val_acc: 0.9800\n",
      "Epoch 106/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0166 - acc: 0.9943 - val_loss: 0.1249 - val_acc: 0.9850\n",
      "Epoch 107/200\n",
      "3500/3500 [==============================] - 0s 127us/step - loss: 0.0181 - acc: 0.9929 - val_loss: 0.1230 - val_acc: 0.9850\n",
      "Epoch 108/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0167 - acc: 0.9934 - val_loss: 0.1177 - val_acc: 0.9850\n",
      "Epoch 109/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0139 - acc: 0.9943 - val_loss: 0.2271 - val_acc: 0.9750\n",
      "Epoch 110/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0167 - acc: 0.9940 - val_loss: 0.1298 - val_acc: 0.9850\n",
      "Epoch 111/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0230 - acc: 0.9906 - val_loss: 0.1069 - val_acc: 0.9850\n",
      "Epoch 112/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0212 - acc: 0.9931 - val_loss: 0.1270 - val_acc: 0.9750\n",
      "Epoch 113/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0174 - acc: 0.9929 - val_loss: 0.1433 - val_acc: 0.9800\n",
      "Epoch 114/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0176 - acc: 0.9937 - val_loss: 0.1635 - val_acc: 0.9750\n",
      "Epoch 115/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0187 - acc: 0.9914 - val_loss: 0.1946 - val_acc: 0.9800\n",
      "Epoch 116/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0170 - acc: 0.9940 - val_loss: 0.1307 - val_acc: 0.9800\n",
      "Epoch 117/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0191 - acc: 0.9931 - val_loss: 0.1708 - val_acc: 0.9750\n",
      "Epoch 118/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0202 - acc: 0.9929 - val_loss: 0.1585 - val_acc: 0.9750\n",
      "Epoch 119/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0233 - acc: 0.9906 - val_loss: 0.2191 - val_acc: 0.9800\n",
      "Epoch 120/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0249 - acc: 0.9906 - val_loss: 0.1280 - val_acc: 0.9800\n",
      "Epoch 121/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0176 - acc: 0.9934 - val_loss: 0.1379 - val_acc: 0.9750\n",
      "Epoch 122/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0176 - acc: 0.9926 - val_loss: 0.1707 - val_acc: 0.9650\n",
      "Epoch 123/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0135 - acc: 0.9969 - val_loss: 0.1797 - val_acc: 0.9800\n",
      "Epoch 124/200\n",
      "3500/3500 [==============================] - 0s 119us/step - loss: 0.0134 - acc: 0.9951 - val_loss: 0.1153 - val_acc: 0.9850\n",
      "Epoch 125/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0194 - acc: 0.9926 - val_loss: 0.1389 - val_acc: 0.9800\n",
      "Epoch 126/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0150 - acc: 0.9943 - val_loss: 0.1371 - val_acc: 0.9800\n",
      "Epoch 127/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0119 - acc: 0.9954 - val_loss: 0.1469 - val_acc: 0.9800\n",
      "Epoch 128/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0123 - acc: 0.9957 - val_loss: 0.1926 - val_acc: 0.9750\n",
      "Epoch 129/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0113 - acc: 0.9960 - val_loss: 0.1895 - val_acc: 0.9800\n",
      "Epoch 130/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.1728 - val_acc: 0.9700\n",
      "Epoch 131/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0122 - acc: 0.9949 - val_loss: 0.1876 - val_acc: 0.9750\n",
      "Epoch 132/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0174 - acc: 0.9931 - val_loss: 0.1539 - val_acc: 0.9800\n",
      "Epoch 133/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0155 - acc: 0.9940 - val_loss: 0.1753 - val_acc: 0.9750\n",
      "Epoch 134/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0187 - acc: 0.9934 - val_loss: 0.1601 - val_acc: 0.9750\n",
      "Epoch 135/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0150 - acc: 0.9931 - val_loss: 0.1608 - val_acc: 0.9800\n",
      "Epoch 136/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0134 - acc: 0.9957 - val_loss: 0.1458 - val_acc: 0.9800\n",
      "Epoch 137/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.1633 - val_acc: 0.9750\n",
      "Epoch 138/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0109 - acc: 0.9971 - val_loss: 0.1153 - val_acc: 0.9850\n",
      "Epoch 139/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0127 - acc: 0.9946 - val_loss: 0.1802 - val_acc: 0.9800\n",
      "Epoch 140/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0127 - acc: 0.9957 - val_loss: 0.1722 - val_acc: 0.9700\n",
      "Epoch 141/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0179 - acc: 0.9934 - val_loss: 0.1640 - val_acc: 0.9700\n",
      "Epoch 142/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0123 - acc: 0.9954 - val_loss: 0.1561 - val_acc: 0.9750\n",
      "Epoch 143/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0203 - acc: 0.9923 - val_loss: 0.1458 - val_acc: 0.9700\n",
      "Epoch 144/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0147 - acc: 0.9957 - val_loss: 0.1778 - val_acc: 0.9800\n",
      "Epoch 145/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0164 - acc: 0.9940 - val_loss: 0.1452 - val_acc: 0.9750\n",
      "Epoch 146/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0142 - acc: 0.9943 - val_loss: 0.1620 - val_acc: 0.9800\n",
      "Epoch 147/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0145 - acc: 0.9949 - val_loss: 0.1461 - val_acc: 0.9800\n",
      "Epoch 148/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0131 - acc: 0.9954 - val_loss: 0.1300 - val_acc: 0.9800\n",
      "Epoch 149/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0135 - acc: 0.9951 - val_loss: 0.1566 - val_acc: 0.9850\n",
      "Epoch 150/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0106 - acc: 0.9954 - val_loss: 0.1691 - val_acc: 0.9800\n",
      "Epoch 151/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0150 - acc: 0.9946 - val_loss: 0.1220 - val_acc: 0.9800\n",
      "Epoch 152/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.1632 - val_acc: 0.9800\n",
      "Epoch 153/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0135 - acc: 0.9934 - val_loss: 0.1630 - val_acc: 0.9800\n",
      "Epoch 154/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.1854 - val_acc: 0.9750\n",
      "Epoch 155/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.1405 - val_acc: 0.9850\n",
      "Epoch 156/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0136 - acc: 0.9963 - val_loss: 0.1726 - val_acc: 0.9800\n",
      "Epoch 157/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0120 - acc: 0.9966 - val_loss: 0.1316 - val_acc: 0.9800\n",
      "Epoch 158/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0128 - acc: 0.9946 - val_loss: 0.1524 - val_acc: 0.9850\n",
      "Epoch 159/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0132 - acc: 0.9949 - val_loss: 0.2071 - val_acc: 0.9850\n",
      "Epoch 160/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.1621 - val_acc: 0.9800\n",
      "Epoch 161/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.1849 - val_acc: 0.9800\n",
      "Epoch 162/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0098 - acc: 0.9957 - val_loss: 0.1943 - val_acc: 0.9850\n",
      "Epoch 163/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.1670 - val_acc: 0.9850\n",
      "Epoch 164/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0135 - acc: 0.9957 - val_loss: 0.1146 - val_acc: 0.9850\n",
      "Epoch 165/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0120 - acc: 0.9951 - val_loss: 0.1274 - val_acc: 0.9850\n",
      "Epoch 166/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0159 - acc: 0.9946 - val_loss: 0.2280 - val_acc: 0.9750\n",
      "Epoch 167/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0122 - acc: 0.9946 - val_loss: 0.1370 - val_acc: 0.9850\n",
      "Epoch 168/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.1938 - val_acc: 0.9750\n",
      "Epoch 169/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0103 - acc: 0.9957 - val_loss: 0.1665 - val_acc: 0.9800\n",
      "Epoch 170/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0144 - acc: 0.9946 - val_loss: 0.1557 - val_acc: 0.9750\n",
      "Epoch 171/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0110 - acc: 0.9960 - val_loss: 0.0962 - val_acc: 0.9850\n",
      "Epoch 172/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.1718 - val_acc: 0.9800\n",
      "Epoch 173/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0106 - acc: 0.9957 - val_loss: 0.1887 - val_acc: 0.9700\n",
      "Epoch 174/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0116 - acc: 0.9960 - val_loss: 0.1468 - val_acc: 0.9800\n",
      "Epoch 175/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0120 - acc: 0.9951 - val_loss: 0.1990 - val_acc: 0.9700\n",
      "Epoch 176/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0132 - acc: 0.9951 - val_loss: 0.2002 - val_acc: 0.9750\n",
      "Epoch 177/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0087 - acc: 0.9963 - val_loss: 0.1581 - val_acc: 0.9800\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0071 - acc: 0.9971 - val_loss: 0.1600 - val_acc: 0.9750\n",
      "Epoch 179/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0074 - acc: 0.9969 - val_loss: 0.1856 - val_acc: 0.9750\n",
      "Epoch 180/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0095 - acc: 0.9969 - val_loss: 0.2079 - val_acc: 0.9750\n",
      "Epoch 181/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0189 - acc: 0.9946 - val_loss: 0.1089 - val_acc: 0.9850\n",
      "Epoch 182/200\n",
      "3500/3500 [==============================] - 0s 125us/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.1407 - val_acc: 0.9750\n",
      "Epoch 183/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0185 - acc: 0.9951 - val_loss: 0.2014 - val_acc: 0.9700\n",
      "Epoch 184/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0149 - acc: 0.9949 - val_loss: 0.1645 - val_acc: 0.9800\n",
      "Epoch 185/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0139 - acc: 0.9946 - val_loss: 0.1947 - val_acc: 0.9650\n",
      "Epoch 186/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.1629 - val_acc: 0.9750\n",
      "Epoch 187/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0073 - acc: 0.9971 - val_loss: 0.1777 - val_acc: 0.9700\n",
      "Epoch 188/200\n",
      "3500/3500 [==============================] - 0s 126us/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.1115 - val_acc: 0.9800\n",
      "Epoch 189/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0114 - acc: 0.9960 - val_loss: 0.1550 - val_acc: 0.9800\n",
      "Epoch 190/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.1601 - val_acc: 0.9750\n",
      "Epoch 191/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0066 - acc: 0.9974 - val_loss: 0.1710 - val_acc: 0.9850\n",
      "Epoch 192/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0083 - acc: 0.9966 - val_loss: 0.2047 - val_acc: 0.9800\n",
      "Epoch 193/200\n",
      "3500/3500 [==============================] - 0s 122us/step - loss: 0.0080 - acc: 0.9977 - val_loss: 0.1595 - val_acc: 0.9850\n",
      "Epoch 194/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0070 - acc: 0.9966 - val_loss: 0.1811 - val_acc: 0.9850\n",
      "Epoch 195/200\n",
      "3500/3500 [==============================] - 0s 123us/step - loss: 0.0146 - acc: 0.9929 - val_loss: 0.1487 - val_acc: 0.9850\n",
      "Epoch 196/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0144 - acc: 0.9949 - val_loss: 0.2478 - val_acc: 0.9750\n",
      "Epoch 197/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.1708 - val_acc: 0.9850\n",
      "Epoch 198/200\n",
      "3500/3500 [==============================] - 0s 120us/step - loss: 0.0098 - acc: 0.9963 - val_loss: 0.1833 - val_acc: 0.9800\n",
      "Epoch 199/200\n",
      "3500/3500 [==============================] - 0s 124us/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.1787 - val_acc: 0.9800\n",
      "Epoch 200/200\n",
      "3500/3500 [==============================] - 0s 121us/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.1530 - val_acc: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# 1. Import libraries and modules\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "from dataset import load_hoda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "# Load pre-shuffled HODA data into train and test sets\n",
    "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda(\n",
    "                                                                        training_sample_size=3500,\n",
    "                                                                        test_sample_size=400,size=28)\n",
    "\n",
    "# Preprocess input data\n",
    "''' 3.1: input data in numpy array format'''\n",
    "x_train = np.array(x_train_original)\n",
    "x_test = np.array(x_test_original)\n",
    "'''3.2 normalize our data values to the range [0, 1]'''\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# 4. Preprocess class labels\n",
    "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n",
    "\n",
    "\n",
    "# test and validation set\n",
    "x_val = x_test[:200]\n",
    "x_test = x_test[200:]\n",
    "y_val = y_test[:200]\n",
    "y_test = y_test[200:]\n",
    "\n",
    "# 5. Define model architecture\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# 6. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 7. Fit model on training data\n",
    "history = model.fit(x_train, y_train,\n",
    "          epochs=200, batch_size=256, validation_data = (x_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcFNW5//HPw74vDriBMGiMGwEcR9CIu/GCUYhoFII3LjG4BJdEf78fKjd6VZIbY7xmMUZi9BodJUQviolLFIlLjMqgLAJBEEFHEBERQVAYeX5/nOqhabqne4aZ7uma7/v1qld3VZ2uerqq55nTp06fMndHRETipUWhAxARkYan5C4iEkNK7iIiMaTkLiISQ0ruIiIxpOQuIhJDSu4xZmYtzWyjmfVpyLKFZGZfMbMG779rZieZ2fKk+cVmdnQuZeuxr7vN7Nr6vl4kF60KHYBsZ2Ybk2Y7AF8AX0bzF7l7RV225+5fAp0aumxz4O4HNMR2zOxC4Bx3Py5p2xc2xLZFaqPk3oS4e01yjWqGF7r7s5nKm1krd6/OR2wi2ejz2LSoWaaImNnNZvYnM3vIzDYA55jZkWb2ipl9YmarzOxXZtY6Kt/KzNzMSqP5B6L1T5rZBjP7p5n1q2vZaP1wM3vLzNab2a/N7B9mdl6GuHOJ8SIzW2pm68zsV0mvbWlm/21ma83sbWBYLcdnoplNSVl2h5ndFj2/0MwWRe/n7ahWnWlbVWZ2XPS8g5ndH8W2ADgszX6XRdtdYGYjouVfA34DHB01eX2UdGxvSHr9xdF7X2tmj5rZXrkcm7oc50Q8ZvasmX1sZh+Y2f9N2s9/RMfkUzOrNLO90zWBmdlLifMcHc8Xov18DEw0s/3NbGb0Xj6KjlvXpNf3jd7jmmj9L82sXRTzQUnl9jKzTWZWkun9ShburqkJTsBy4KSUZTcDW4DTCP+Y2wOHA0MI38L2Bd4CxkflWwEOlEbzDwAfAeVAa+BPwAP1KLs7sAEYGa37EbAVOC/De8klxseArkAp8HHivQPjgQVAb6AEeCF8bNPuZ19gI9AxadsfAuXR/GlRGQNOADYDA6J1JwHLk7ZVBRwXPb8V+DvQHegLLEwpexawV3ROvhPFsEe07kLg7ylxPgDcED0/OYpxENAO+C3wXC7Hpo7HuSuwGrgCaAt0AQZH664B5gL7R+9hELAb8JXUYw28lDjP0XurBi4BWhI+j18FTgTaRJ+TfwC3Jr2fN6Pj2TEqf1S0bjIwKWk/VwHTCv13WMxTwQPQlOHEZE7uz2V53dXAn6Pn6RL275LKjgDerEfZC4AXk9YZsIoMyT3HGI9IWv+/wNXR8xcIzVOJdaekJpyUbb8CfCd6Phx4q5ayfwF+ED2vLbm/m3wugEuTy6bZ7pvAN6Pn2ZL7fcBPktZ1IVxn6Z3t2NTxOP87UJmh3NuJeFOW55Lcl2WJ4UxgVvT8aOADoGWackcB7wAWzc8BRjX031VzmtQsU3zeS54xswPN7K/R1+xPgRuBHrW8/oOk55uo/SJqprJ7J8fh4a+xKtNGcowxp30BK2qJF+BBYEz0/DtAzUVoMzvVzF6NmiU+IdSaaztWCXvVFoOZnWdmc6OmhU+AA3PcLoT3V7M9d/8UWAf0SiqT0znLcpz3AZZmiGEfQoKvj9TP455mNtXM3o9i+J+UGJZ7uHi/A3f/B+FbwFAz6w/0Af5az5gEtbkXo9RugHcRaopfcfcuwI8JNenGtIpQswTAzIwdk1GqXYlxFSEpJGTrqvkn4CQz601oNnowirE98DDwU0KTSTfgbznG8UGmGMxsX+BOQtNESbTdfyVtN1u3zZWEpp7E9joTmn/ezyGuVLUd5/eA/TK8LtO6z6KYOiQt2zOlTOr7+xmhl9fXohjOS4mhr5m1zBDHH4FzCN8yprr7FxnKSQ6U3ItfZ2A98Fl0QeqiPOzzL0CZmZ1mZq0I7bg9GynGqcCVZtYrurj2/2or7O6rCU0H9wKL3X1JtKotoR14DfClmZ1KaBvONYZrzaybhd8BjE9a14mQ4NYQ/s9dSKi5J6wGeidf2EzxEPA9MxtgZm0J/3xedPeM34RqUdtxng70MbPxZtbGzLqY2eBo3d3AzWa2nwWDzGw3wj+1DwgX7lua2TiS/hHVEsNnwHoz24fQNJTwT2At8BMLF6nbm9lRSevvJzTjfIeQ6GUXKLkXv6uAcwkXOO8i1FwbVZRAzwZuI/yx7ge8QaixNXSMdwIzgPnALELtO5sHCW3oDybF/AnwQ2Aa4aLkmYR/Urm4nvANYjnwJEmJx93nAb8CXovKHAi8mvTaZ4AlwGozS25eSbz+KULzybTo9X2AsTnGlSrjcXb39cA3gDMIF3DfAo6NVv8ceJRwnD8lXNxsFzW3fR+4lnBx/Ssp7y2d64HBhH8y04FHkmKoBk4FDiLU4t8lnIfE+uWE87zF3V+u43uXFImLFyL1Fn3NXgmc6e4vFjoeKV5m9kfCRdobCh1LsdOPmKRezGwY4Wv254SudNWE2qtIvUTXL0YCXyt0LHGgZhmpr6HAMsLX9WHAt3QBTOrLzH5K6Gv/E3d/t9DxxIGaZUREYkg1dxGRGCpYm3uPHj28tLS0ULsXESlKs2fP/sjda+t6DBQwuZeWllJZWVmo3YuIFCUzy/YrbUDNMiIisaTkLiISQ0ruIiIxpOQuIhJDSu4iIjGUNbmb2T1m9qGZvZlhvUW32VpqZvPMrKzhwxSRxlJRAaWlYAatWoXH0tKwPFPZFi0ylym0uryf1Nfk+r5Sy196aRM8Ltnu5gEcA5QR3YUnzfpTCCPlGXAE8Goudwk57LDDXKQ+HnjAvW9fd7Pw+MADjb+/khJ3CFOLFuGxpMS9Y8f0yxPlW7YMj337ul9ySe1xp+4neerYcedtJu/HLP3rEjEl77+28ummbGUTsaV7X4lzlUuMdYmptuOzq++noabkmJL3mXxO6vPZJcMdtVKnrAXCtiitJbnfBYxJml8M7JVtm0ru8ZMt6aYmr5KS9GVSt1Fb0qvLH1O6ZakJOl3S0aSpsaYOHeqe4POZ3P8CDE2an0F0Q+I0ZccBlUBlnz596vaOGsmKFe5PPbXz8vffd5861X3btty2s3mz+/33u2/YUP9Y1qxxf+gh9+rq+m+jrj7/PLzPLVvCfHJyzaVmmO2De8kludeoNGlqjlPfvnX7m81ncv9rmuR+WLZtNoWa+7Zt7kOGhKMwadL25W+/vf2r5CWXuH/5Ze3b2bjR/aSTQvmvf939k0/qHktVlfsBB4RtnHOO+9atdd9GOqk14eSv5omv96nPNWnSlL/JrG5/02qWycH06eEIHHJIeLz77pCo+/Rx32039/PPD8vPO297bfrOO9332cf9mWdC4uzcOZycFi3cx493b93a/bDD3FeudB87NizPNLVq5f6jH7kvW+a+775hWxddtP2EJ5ft1s192rTcmij22su9U6fCf2g1adKUfWqsmntDjC0zHRhvZlOAIcB6d1/VANttNHPmwJ//HKavfAVmz4aTToL/+A94990wPf88HH10uPJ9/fXwwQfQuzfcfTe0bw/f/CZs3Qpf/zocfzwcdxyceCIMHw6jRsG++8Lnn8O4cbD77unjWLoUbrsNfvvbcJW9Sxe4666wLnHqEz75BE4/Pbf3t6pJH30RSejQASZNaqSNZ8v+hBv4rgK2AlXA94CLgYuj9QbcAbxNuP9h2vb21CmfNffUdvNEE0q7du6PPBKWvfDC9v+kp5yyY/lbbw3tx61ahSaTVavcjznGfdQo902bdt7fs8+G2v9dd9V+EXHbNvcbbnDv2rXwtQdNzXdKXDju3dt9773d27cP84mmunTXWxJlGnL/DT0l3k9dXtOhQ+5lM/VgynSBPvX9NoneMo0x5Su5z58fmjtmzgzzmzeHpH7llTuX/bd/C0fk9dd3bZ/J3b9q+2Bk+xBoqv2PA8K5zNd+Ez0bUq9jfPvbYf03vuH+hz9kv8ZRWwKoSw+iXLqDJn8Wk7tl1iepPP10eP1VV4X5++93b9s2LGvfPvvF96OOarhrSckaq2vstm3u114bYt9zT/cFCwofk7u7knvk6qvDuzz88HCyZs4M89On71y2qsr9L3/JvK3aTliu3fXiPOVSAyspcb/33pD0+vTZORlk6qKYmvTWrNn+rSvbuXn1VfdXXnH/17/C9tu0CUk4UavL9MeX6x/oF1+EHkebN2f+7NRmxgz3d9+t32vzadu20Jtr48bty957L31vs4S//tX95z93v+++7B0TmqrHHnNfvrzQUWyn5O7hw9S7t3v37uGdTpvmPnFiqMGsX1+3bT3wwM5f2eLa1a+kJPsPbrIdq+Rj0r174//QKFfXXBMuWosUq1yTe8HuoVpeXu6NfbOOF1+EY46B++4LFy0+/xw6dYLOneGVV+q2rdJSWJFmiHyzkMKKTUkJnHUWPPFEuIDcp084RmPHFjoyEamNmc129/Js5WI9cNi994aeLaNGwYMPwoYNsHBh6NVSV+9muB97PhN7i+hs9e0LDzywc537gQfCOoCWLbeXveSS8Gi2/bUffRR66SxfDtu2hUcldpH4KNht9hqTO9x0U0ju48eH2vphh8Hf/w5XXQX//u+5baeiAq64AtaubdRwd1BSAr/8Zf0S7dixStAiEsSu5u4O11wT+qafey7cfvv2dQMGwDPPwIEHZn59RQX06BFqueec03CJvUOH8I3BLP36kpLtNWolaBHZVbFL7hMnws9+Fpoi7rlne/NELioq4PzzGyahd+wYEnaiKWTyZHj2Wbj//p2bSNyV1EWkYcXqguqnn8Iee8C3vhXa2DPVkjPJdNE0Vy1bhou3StIi0lia5QXV6dNDj5jx4+ue2Csqdi2xt2mjxC4iTUeskvtDD4UufUcemb1s8p1UOnUK7ev1VVISmoCU2EWkqYhNcl+7Fv72Nzj77O1dBjOpqAgDeq1YEdq7P/sst31k6oqo9nIRaWpi0xXyiSegujok92yuuw42bcptu7vSNVFEpFBik9xffTX0UBk0qPZydWlb79s3/LhHRKTYxKZZZtas8EOl2ro+Xnpp7j9gMmvEcZZFRBpZLJL7li3hBhyDB6dfn/hh0p135jZcgBlcfLGaYkSkeMWiWWb+/JDgDz9853WJi6e5trFD+KGREruIFLNY1NxnzQqP6ZJ7XS6eQmhnV2IXkWIXi+T+2muhV0tp6c7rMo3mmE6j3s9QRCSPYpHcZ88OtfZ0v0rt06f213bqtOP4L6q1i0gcxCK5r16dOYmfckr6pJ8YhXHDBo1nLiLxk1NyN7NhZrbYzJaa2YQ06/ua2Qwzm2dmfzez3g0famYbNoQaeLJMPWTMwoiR+lWpiMRZ1uRuZi2BO4DhwMHAGDM7OKXYrcAf3X0AcCPw04YONJMvvwwXTDt33r4s0UMm3dC97uHXrCIicZZLzX0wsNTdl7n7FmAKMDKlzMHAjOj5zDTrG01iXJjk5J6th0xdLrKKiBSjXJJ7L+C9pPmqaFmyucAZ0fPTgc5mVpK6ITMbZ2aVZla5Zs2a+sS7kw0bwmNycs+WvLNdZBURKXa5JPd0I6On/s7zauBYM3sDOBZ4H6je6UXuk9293N3Le/bsWedg00kk9+Q299qSt7o7ikhzkEtyrwL2SZrvDaxMLuDuK919lLsfClwXLVvfYFHWYuPG8Jhcc580KSTxVCUl6u4oIs1DLsl9FrC/mfUzszbAaGB6cgEz62FmiW1dA9zTsGFmlq5ZZuzYkMRT71WqHjIi0lxkTe7uXg2MB54GFgFT3X2Bmd1oZiOiYscBi83sLWAPIG8NH6nNMok7LCVGf7z/fvVhF5HmJ6eBw9z9CeCJlGU/Tnr+MPBww4aWm+RmmdRBwlasCPOg5C4izUvR/0I1uVkmXRfITZvCchGR5iQ2yb1Tp8xdINWvXUSam1gl90xdINWvXUSam6JP7hs3hnuntmiRvguk+rWLSHNU9Mk9ddCw9u23P1e/dhFpror+NnsbNqTvKQOweXPh4hIRKaSir7lv3KieMiIiqYo+uSdq7uopIyKyXSySu3rKiIjsqOiTe6JZRj1lRES2K/rknmiWSTdYmHrKiEhzFYveMlVVYbCwd98NzTD336+kLiLNW1En923bQrPMs89CdXRrEA0WJiJS5M0yia6P1dU7L1cXSBFpzoo6uSfGlUlHXSBFpDmLbXJXF0gRac6KOrknbtTRps2Oy9UFUkSau6JO7oma+49+pC6QIiLJirq3TCK5n346/PSnhY1FRKQpiUXNvXPnwsYhItLU5JTczWyYmS02s6VmNiHN+j5mNtPM3jCzeWZ2SsOHurOPPw6PXbrkY28iIsUja3I3s5bAHcBw4GBgjJkdnFJsIjDV3Q8FRgO/behA03n5ZdhjD9h773zsTUSkeORScx8MLHX3Ze6+BZgCjEwp40Ci/twVWNlwIabnDs89ByecEC6kiojIdrlcUO0FvJc0XwUMSSlzA/A3M7sM6Aic1CDR1WLRIvjgg5DcRURkR7nU3NPViz1lfgzwP+7eGzgFuN/Mdtq2mY0zs0ozq1yzZk3do03y3HPh8cQTd2kzIiKxlEtyrwL2SZrvzc7NLt8DpgK4+z+BdkCP1A25+2R3L3f38p49e9Yv4siMGdCvX5hERGRHuST3WcD+ZtbPzNoQLphOTynzLnAigJkdREjuu1Y1z+Lll+HYYxtzDyIixStrcnf3amA88DSwiNArZoGZ3WhmI6JiVwHfN7O5wEPAee6e2nTTYNxDN0j1khERSS+nfu7u/oS7f9Xd93P3SdGyH7v79Oj5Qnc/yt0Huvsgd/9bYwa9eXMY5rdLF6ioCDfqaNEiPFZUNOaeRUSKQ1H+QvXTT8Pjv/4VbsyxYkWozSdu1KEELyLNXVEn98cf337DjgTdqENEpMiT+9q16dfrRh0i0twVdXLfY4/063WjDhFp7oo6uV92WbgxRzLdqENEpMiT++jR4cYculGHiMiOivJmHYnk3qVLSORK5iIiOyrqmrvGcRcRSa9ok3vbtmESEZGdFW1yV61dRCQzJXcRkRhSchcRiSEldxGRGFJyFxGJISV3EZEYUnIXEYkhJXcRkRgquuT+xRdhWrZMd2ASEcmk6MaW2bAhPD76KGzdGp4n7sAEGmdGRASKsOaeGFcmkdgTdAcmEZHtija5p6M7MImIBDkldzMbZmaLzWypmU1Is/6/zWxONL1lZp80fKhBbcldd2ASEQmytrmbWUvgDuAbQBUwy8ymu/vCRBl3/2FS+cuAQxshVmB7cm/bNlxYTdAdmEREtsul5j4YWOruy9x9CzAFGFlL+THAQw0RXDqJ5H7zzboDk4hIJrn0lukFvJc0XwUMSVfQzPoC/YDnMqwfB4wD6FPPNpREcj/nHLj66nptQkQk9nKpuVuaZZ6h7GjgYXf/Mt1Kd5/s7uXuXt6zZ89cY9yB7sIkIpJdLsm9Ctgnab43sDJD2dE0YpMMwHe/C//4B7Rv35h7EREpbrk0y8wC9jezfsD7hAT+ndRCZnYA0B34Z4NGmGLPPcMkIiKZZa25u3s1MB54GlgETHX3BWZ2o5mNSCo6Bpji7pmabEREJE9yGn7A3Z8AnkhZ9uOU+RsaLiwREdkVRfcLVRERyU7JXUQkhpTcRURiSMldRCSGlNxFRGJIyV1EJIaU3EVEYkjJXUQkhpTcRURiSMldRCSGlNxFRGJIyV1EJIaU3EVEYkjJXUQkhpTcRURiSMldRCSGlNxFRGJIyV1EJIaU3EVEYkjJXUQkhnJK7mY2zMwWm9lSM5uQocxZZrbQzBaY2YMNG6aIiNRFq2wFzKwlcAfwDaAKmGVm0919YVKZ/YFrgKPcfZ2Z7d5YAYuISHa51NwHA0vdfZm7bwGmACNTynwfuMPd1wG4+4cNG6aIiNRFLsm9F/Be0nxVtCzZV4Gvmtk/zOwVMxuWbkNmNs7MKs2scs2aNfWLWEREssoluVuaZZ4y3wrYHzgOGAPcbWbddnqR+2R3L3f38p49e9Y1VhERyVEuyb0K2CdpvjewMk2Zx9x9q7u/AywmJPtGUVEBpaXQokV4rKhorD2JiBSnXJL7LGB/M+tnZm2A0cD0lDKPAscDmFkPQjPNsoYMNKGiAsaNgxUrwD08jhunBC8ikixrcnf3amA88DSwCJjq7gvM7EYzGxEVexpYa2YLgZnA/3H3tY0R8HXXwaZNOy7btCksFxGRwNxTm8/zo7y83CsrK+v8uhYtQo09lRls29YAgYmINGFmNtvdy7OVK7pfqPbpU7flIiLNUdEl90mToEOHHZd16BCWi4hIUHTJfexYmDwZ+vYNTTF9+4b5sWMLHZmISNORdfiBpmjsWCVzEZHaFF3NXUREslNyFxGJISV3EZEYUnIXEYkhJXcRkRhSchcRiSEldxGRGFJyFxGJISV3EZEYUnIXEYkhJXcRkRhSchcRiSEldxGRGFJyFxGJISV3EZEYUnIXEYkhJXcRkRjKKbmb2TAzW2xmS81sQpr155nZGjObE00XNnyoIiKSq6y32TOzlsAdwDeAKmCWmU1394UpRf/k7uMbIUYREamjXGrug4Gl7r7M3bcAU4CRjRuWiIjsilySey/gvaT5qmhZqjPMbJ6ZPWxm+6TbkJmNM7NKM6tcs2ZNPcIVEZFc5JLcLc0yT5l/HCh19wHAs8B96Tbk7pPdvdzdy3v27Fm3SEVEJGe5JPcqILkm3htYmVzA3de6+xfR7O+BwxomPBERqY9ckvssYH8z62dmbYDRwPTkAma2V9LsCGBRw4UoIiJ1lbW3jLtXm9l44GmgJXCPuy8wsxuBSnefDlxuZiOAauBj4LxGjFlERLIw99Tm8/woLy/3ysrKguxbRKRYmdlsdy/PVk6/UBURiSEldxGRGFJyFxGJISV3EZEYUnIXEYkhJXcRkRhSchcRiSEldxGRGFJyFxGJISV3EZEYUnIXEYkhJXcRkRhSchcRiSEldxGRGFJyFxGJISV3EZEYUnIXEYmhrLfZE5F42bp1K1VVVXz++eeFDkVq0a5dO3r37k3r1q3r9Xold5Fmpqqqis6dO1NaWoqZFTocScPdWbt2LVVVVfTr169e21CzjEgz8/nnn1NSUqLE3oSZGSUlJbv07Sqn5G5mw8xssZktNbMJtZQ708zczLLevFVECkeJvenb1XOUNbmbWUvgDmA4cDAwxswOTlOuM3A58OouRSQiIrssl5r7YGCpuy9z9y3AFGBkmnI3AbcAukojEiMVFVBaCi1ahMeKil3b3tq1axk0aBCDBg1izz33pFevXjXzW7ZsyWkb559/PosXL661zB133EHFrgZbxHK5oNoLeC9pvgoYklzAzA4F9nH3v5jZ1Zk2ZGbjgHEAffr0qXu0IpJXFRUwbhxs2hTmV6wI8wBjx9ZvmyUlJcyZMweAG264gU6dOnH11TumDXfH3WnRIn3989577826nx/84Af1CzAmcqm5p2v48ZqVZi2A/wauyrYhd5/s7uXuXt6zZ8/coxSRgrjuuu2JPWHTprC8oS1dupT+/ftz8cUXU1ZWxqpVqxg3bhzl5eUccsgh3HjjjTVlhw4dypw5c6iurqZbt25MmDCBgQMHcuSRR/Lhhx8CMHHiRG6//faa8hMmTGDw4MEccMABvPzyywB89tlnnHHGGQwcOJAxY8ZQXl5e848n2fXXX8/hhx9eE597SIFvvfUWJ5xwAgMHDqSsrIzly5cD8JOf/ISvfe1rDBw4kOsa42DlIJfkXgXskzTfG1iZNN8Z6A/83cyWA0cA03VRVaT4vftu3ZbvqoULF/K9732PN954g169evFf//VfVFZWMnfuXJ555hkWLly402vWr1/Psccey9y5cznyyCO555570m7b3Xnttdf4+c9/XvOP4te//jV77rknc+fOZcKECbzxxhtpX3vFFVcwa9Ys5s+fz/r163nqqacAGDNmDD/84Q+ZO3cuL7/8MrvvvjuPP/44Tz75JK+99hpz587lqquy1nsbRS7JfRawv5n1M7M2wGhgemKlu6939x7uXurupcArwAh3r2yUiEUkbzK1njZWq+p+++3H4YcfXjP/0EMPUVZWRllZGYsWLUqb3Nu3b8/w4cMBOOyww2pqz6lGjRq1U5mXXnqJ0aNHAzBw4EAOOeSQtK+dMWMGgwcPZuDAgTz//PMsWLCAdevW8dFHH3HaaacB4UdHHTp04Nlnn+WCCy6gffv2AOy22251PxANIGtyd/dqYDzwNLAImOruC8zsRjMb0dgBikjhTJoEHTrsuKxDh7C8MXTs2LHm+ZIlS/jlL3/Jc889x7x58xg2bFjaft9t2rSped6yZUuqq6vTbrtt27Y7lUk0r9Rm06ZNjB8/nmnTpjFv3jwuuOCCmjjSdVd09ybR1TSnfu7u/oS7f9Xd93P3SdGyH7v79DRlj1OtXSQexo6FyZOhb18wC4+TJ9f/YmpdfPrpp3Tu3JkuXbqwatUqnn766Qbfx9ChQ5k6dSoA8+fPT/vNYPPmzbRo0YIePXqwYcMGHnnkEQC6d+9Ojx49ePzxx4Hw47BNmzZx8skn84c//IHNmzcD8PHHHzd43LnQ8AMiUquxY/OTzFOVlZVx8MEH079/f/bdd1+OOuqoBt/HZZddxne/+10GDBhAWVkZ/fv3p2vXrjuUKSkp4dxzz6V///707duXIUO2dxasqKjgoosu4rrrrqNNmzY88sgjnHrqqcydO5fy8nJat27Naaedxk033dTgsWdjuXwtaQzl5eVeWakKvki+LVq0iIMOOqjQYTQJ1dXVVFdX065dO5YsWcLJJ5/MkiVLaNWqadR7050rM5vt7lk7rDSNdyAiUgAbN27kxBNPpLq6GnfnrrvuajKJfVfF412IiNRDt27dmD17dqHDaBQaFVJEJIaU3EVEYkjJXUQkhpTcRURiSMldRPLquOOO2+kHSbfffjuXXnppra/r1KkTACtXruTMM8/MuO1sXaxvv/12NiWNhnbKKafwySef5BJ6UVFyF5G8GjNmDFOmTNlh2ZQpUxgzZkxOr9977715+OGH673/1OT+xBNP0K1bt3pvr6lSV0iRZuzKKyHNCLe7ZNDl79r4AAAKg0lEQVQgiEbaTevMM89k4sSJfPHFF7Rt25bly5ezcuVKhg4dysaNGxk5ciTr1q1j69at3HzzzYwcueO9gZYvX86pp57Km2++yebNmzn//PNZuHAhBx10UM1P/gEuueQSZs2axebNmznzzDP5z//8T371q1+xcuVKjj/+eHr06MHMmTMpLS2lsrKSHj16cNttt9WMKnnhhRdy5ZVXsnz5coYPH87QoUN5+eWX6dWrF4899ljNwGAJjz/+ODfffDNbtmyhpKSEiooK9thjDzZu3Mhll11GZWUlZsb111/PGWecwVNPPcW1117Ll19+SY8ePZgxY0bDnQSU3EUkz0pKShg8eDBPPfUUI0eOZMqUKZx99tmYGe3atWPatGl06dKFjz76iCOOOIIRI0ZkHIjrzjvvpEOHDsybN4958+ZRVlZWs27SpEnstttufPnll5x44onMmzePyy+/nNtuu42ZM2fSo0ePHbY1e/Zs7r33Xl599VXcnSFDhnDsscfSvXt3lixZwkMPPcTvf/97zjrrLB555BHOOeecHV4/dOhQXnnlFcyMu+++m1tuuYVf/OIX3HTTTXTt2pX58+cDsG7dOtasWcP3v/99XnjhBfr169co488ouYs0Y7XVsBtTomkmkdwTtWV359prr+WFF16gRYsWvP/++6xevZo999wz7XZeeOEFLr/8cgAGDBjAgAEDatZNnTqVyZMnU11dzapVq1i4cOEO61O99NJLnH766TUjU44aNYoXX3yRESNG0K9fPwYNGgRkHla4qqqKs88+m1WrVrFlyxb69esHwLPPPrtDM1T37t15/PHHOeaYY2rKNMawwEXV5t7Q93IUkcL41re+xYwZM3j99dfZvHlzTY27oqKCNWvWMHv2bObMmcMee+yRdpjfZOlq9e+88w633norM2bMYN68eXzzm9/Mup3axtlKDBcMmYcVvuyyyxg/fjzz58/nrrvuqtlfuiGA8zEscNEk98S9HFesAPft93JUghcpPp06deK4447jggsu2OFC6vr169l9991p3bo1M2fOZMWKFbVu55hjjqm5Cfabb77JvHnzgDBccMeOHenatSurV6/mySefrHlN586d2bBhQ9ptPfroo2zatInPPvuMadOmcfTRR+f8ntavX0+vXr0AuO+++2qWn3zyyfzmN7+pmV+3bh1HHnkkzz//PO+88w7QOMMCF01yz+e9HEWk8Y0ZM4a5c+fW3AkJYOzYsVRWVlJeXk5FRQUHHnhgrdu45JJL2LhxIwMGDOCWW25h8ODBQLir0qGHHsohhxzCBRdcsMNwwePGjWP48OEcf/zxO2yrrKyM8847j8GDBzNkyBAuvPBCDj300Jzfzw033MC3v/1tjj766B3a8ydOnMi6devo378/AwcOZObMmfTs2ZPJkyczatQoBg4cyNlnn53zfnJVNEP+tmgRauypzGDbtgYMTCTmNORv8diVIX+Lpuae73s5iogUs6JJ7vm+l6OISDErmuReyHs5isRNoZpjJXe7eo5ySu5mNszMFpvZUjObkGb9xWY238zmmNlLZnbwLkWVwdixsHx5aGNfvlyJXaQ+2rVrx9q1a5XgmzB3Z+3atbRr167e28j6IyYzawncAXwDqAJmmdl0d0++TfiD7v67qPwI4DZgWL2jEpFG07t3b6qqqlizZk2hQ5FatGvXjt69e9f79bn8QnUwsNTdlwGY2RRgJFCT3N3906TyHQFVCUSaqNatW9f8MlLiK5fk3gt4L2m+ChiSWsjMfgD8CGgDnNAg0YmISL3k0uae7jeyO9XM3f0Od98P+H/AxLQbMhtnZpVmVqmvhCIijSeX5F4F7JM03xtYWUv5KcC30q1w98nuXu7u5T179sw9ShERqZNcmmVmAfubWT/gfWA08J3kAma2v7sviWa/CSwhi9mzZ39kZrUPHJFZD+Cjer62sTXV2BRX3SiuumuqscUtrr65FMqa3N292szGA08DLYF73H2Bmd0IVLr7dGC8mZ0EbAXWAefmsN16V93NrDKXn98WQlONTXHVjeKqu6YaW3ONK6fx3N39CeCJlGU/Tnp+RQPHJSIiu6BofqEqIiK5K9bkPrnQAdSiqcamuOpGcdVdU42tWcZVsCF/RUSk8RRrzV1ERGqh5C4iEkNFl9yzjVCZxzj2MbOZZrbIzBaY2RXR8hvM7P1ohMw5ZnZKAWJbnjRKZ2W0bDcze8bMlkSP3fMc0wFJx2SOmX1qZlcW6niZ2T1m9qGZvZm0LO0xsuBX0WdunpmV5Tmun5vZv6J9TzOzbtHyUjPbnHTsfpfnuDKeOzO7Jjpei83s3xorrlpi+1NSXMvNbE60PC/HrJb8kL/PmLsXzUToZ/82sC9hDJu5wMEFimUvoCx63hl4CzgYuAG4usDHaTnQI2XZLcCE6PkE4GcFPo8fEH6MUZDjBRwDlAFvZjtGwCnAk4ShOI4AXs1zXCcDraLnP0uKqzS5XAGOV9pzF/0dzAXaAv2iv9mW+YwtZf0vgB/n85jVkh/y9hkrtpp7zQiV7r6FMNTByEIE4u6r3P316PkGYBFhkLWmaiSQuCX7fWQYIiJPTgTedvf6/kJ5l7n7C0DqLeczHaORwB89eAXoZmZ75Ssud/+bu1dHs68QhgDJqwzHK5ORwBR3/8Ld3wGWEv528x6bmRlwFvBQY+0/Q0yZ8kPePmPFltzTjVBZ8IRqZqXAocCr0aLx0Vere/Ld/BFx4G9mNtvMxkXL9nD3VRA+eMDuBYgrYTQ7/rEV+nglZDpGTelzdwGhhpfQz8zeMLPnzezoAsST7tw1peN1NLDatw+PAnk+Zin5IW+fsWJL7jmNUJlPZtYJeAS40sO49ncC+wGDgFWEr4T5dpS7lwHDgR+Y2TEFiCEtM2sDjAD+HC1qCscrmybxuTOz64BqoCJatAro4+6HEobbftDMuuQxpEznrkkcr8gYdqxI5PWYpckPGYumWbZLx6zYkntdR6hsVGbWmnDiKtz9fwHcfbW7f+nu24Df04hfRzNx95XR44fAtCiG1YmvedHjh/mOKzIceN3dV0cxFvx4Jcl0jAr+uTOzc4FTgbEeNdJGzR5ro+ezCW3bX81XTLWcu4IfLwAzawWMAv6UWJbPY5YuP5DHz1ixJfeaESqjGuBoYHohAona8v4ALHL325KWJ7eTnQ68mfraRo6ro5l1TjwnXIx7k3CcEgO6nQs8ls+4kuxQkyr08UqR6RhNB74b9Wg4Alif+GqdD2Y2jHCfhBHuvilpeU8Lt8HEzPYF9geW5TGuTOduOjDazNpaGE12f+C1fMWV5CTgX+5elViQr2OWKT+Qz89YY181buiJcFX5LcJ/3OsKGMdQwtemecCcaDoFuB+YHy2fDuyV57j2JfRUmAssSBwjoASYQRiOeQawWwGOWQdgLdA1aVlBjhfhH8wqwkimVcD3Mh0jwlfmO6LP3HygPM9xLSW0xyY+Z7+Lyp4RneO5wOvAaXmOK+O5A66LjtdiYHi+z2W0/H+Ai1PK5uWY1ZIf8vYZ0/ADIiIxVGzNMiIikgMldxGRGFJyFxGJISV3EZEYUnIXEYkhJXcRkRhSchcRiaH/D97S/ZvGdA/GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> دوره مقدماتی یادگیری عمیق<br>علیرضا اخوان پور<br> <br>\n",
    "</div>\n",
    "<a href=\"http://class.vision\">Class.Vision</a> - <a href=\"http://AkhavanPour.ir\">AkhavanPour.ir</a> - <a href=\"https://github.com/Alireza-Akhavan/\">GitHub</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbpresent": {
   "slides": {
    "300ee14f-a043-486e-b274-7ff253907cd7": {
     "id": "300ee14f-a043-486e-b274-7ff253907cd7",
     "prev": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "regions": {
      "26dc3f39-a230-447c-af4c-f5e5b2fb7835": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c58440a5-3f8f-4f37-9c79-6bf766209406",
        "part": "whole"
       },
       "id": "26dc3f39-a230-447c-af4c-f5e5b2fb7835"
      }
     }
    },
    "878aa53a-1444-4100-8f50-7a408191c579": {
     "id": "878aa53a-1444-4100-8f50-7a408191c579",
     "prev": null,
     "regions": {
      "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "588ee1fa-64b5-453b-ade7-8e6b2515821c",
        "part": "whole"
       },
       "id": "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3"
      }
     }
    },
    "96ffe88e-7b50-43de-afdd-942e564f4e3e": {
     "id": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "prev": "878aa53a-1444-4100-8f50-7a408191c579",
     "regions": {
      "b7e52e12-489a-468d-b10c-af2024fd2856": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de829a92-1fb6-44ad-a2c6-fc1001e1f6e1",
        "part": "whole"
       },
       "id": "b7e52e12-489a-468d-b10c-af2024fd2856"
      }
     }
    },
    "cb74e0bc-4513-4d13-b7f1-14c3078a7927": {
     "id": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "prev": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "regions": {
      "444878ee-68f3-4abb-acff-a7079b21e86d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "25f3f538-1ee8-4d98-a6bb-14cbeb7a702d",
        "part": "whole"
       },
       "id": "444878ee-68f3-4abb-acff-a7079b21e86d"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/z-arabi/SRU-deeplearning-workshop/blob/master/19_Basic_regression_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Regression with Keras"
      ],
      "metadata": {
        "id": "X8iIN-GlVxzz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykY0-GLSVvqj"
      },
      "source": [
        "## House Price Estimation Dataset\n",
        "\n",
        "<div style=\"text-align:right;font-family:Tahoma\">\n",
        "House price estimation from visual and textual features\n",
        "</div>\n",
        "<p>\n",
        "<a href=\"https://github.com/emanhamed/Houses-dataset\" target=\"_blank\">\n",
        "https://github.com/emanhamed/Houses-dataset\n",
        "</a>\n",
        "<br>\n",
        "<a href=\"https://arxiv.org/pdf/1609.08399.pdf\" target=\"_blank\">\n",
        "https://arxiv.org/pdf/1609.08399.pdf\n",
        "</a>\n",
        "    \n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CA6FGtlnVvqk"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import locale\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/emanhamed/Houses-dataset.git\n",
        "%cd Houses-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEiSGzehWhhJ",
        "outputId": "a553b7ed-b7a7-4704-c1df-907ce8413421"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Houses-dataset'...\n",
            "remote: Enumerating objects: 2166, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 2166 (delta 0), reused 0 (delta 0), pack-reused 2165\u001b[K\n",
            "Receiving objects: 100% (2166/2166), 176.26 MiB | 26.30 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "Updating files: 100% (2144/2144), done.\n",
            "/content/Houses-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "964DOzXOVvqn"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Attribute Information:\n",
        "\n",
        "Number of Bedrooms\n",
        "Number of bathrooms\n",
        "Area\n",
        "Zipcode\n",
        "Price\n",
        "'''\n",
        "cols = [\"bedrooms\", \"bathrooms\", \"area\", \"zipcode\", \"price\"]\n",
        "df = pd.read_csv(\"Houses Dataset/HousesInfo.txt\", sep=\" \", header=None, names=cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "VpNBs6FcVvqo",
        "outputId": "1ea91865-82b1-4b48-8135-a000280c8fb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   bedrooms  bathrooms  area  zipcode   price\n",
              "0         4        4.0  4053    85255  869500\n",
              "1         4        3.0  3343    36372  865200\n",
              "2         3        4.0  3923    85266  889000\n",
              "3         5        5.0  4022    85262  910000\n",
              "4         3        4.0  4116    85266  971226"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8749e056-2d89-4121-8f3d-0b74a73e93d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>area</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4053</td>\n",
              "      <td>85255</td>\n",
              "      <td>869500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3343</td>\n",
              "      <td>36372</td>\n",
              "      <td>865200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3923</td>\n",
              "      <td>85266</td>\n",
              "      <td>889000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4022</td>\n",
              "      <td>85262</td>\n",
              "      <td>910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4116</td>\n",
              "      <td>85266</td>\n",
              "      <td>971226</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8749e056-2d89-4121-8f3d-0b74a73e93d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8749e056-2d89-4121-8f3d-0b74a73e93d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8749e056-2d89-4121-8f3d-0b74a73e93d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-397dbeb2-4278-47c0-8995-c8c6fa5940fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-397dbeb2-4278-47c0-8995-c8c6fa5940fd')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-397dbeb2-4278-47c0-8995-c8c6fa5940fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRW-HUtmVvqq",
        "outputId": "697f660e-a097-46a2-fd88-c139f9be24b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[36372 60002 60016 60046 62025 62034 62088 62214 62234 62249 81418 81521\n",
            " 81524 85255 85262 85266 85331 85377 90038 90211 90265 90803 91752 91901\n",
            " 91915 92021 92040 92253 92276 92543 92677 92692 92802 92880 93105 93111\n",
            " 93314 93446 93510 93720 93924 94501 94531 94565 94568 95008 95220 96019\n",
            " 98021] [  1   3   2   1   2   1   1   4   7   1   2   1  11  12   9  11   1   3\n",
            "   1   1   1   1   3  32   1  11   1   2 100   1  26   2   9  49   1  11\n",
            "   1  54  60   1   1  41  22   1   1   1  10  12   4]\n"
          ]
        }
      ],
      "source": [
        "zipcodes, counts = np.unique(df[\"zipcode\"], return_counts=True)\n",
        "print(zipcodes, counts)\n",
        "# dict(zip(zipcodes, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzyK0-bSVvqq",
        "outputId": "13e59e68-4f9f-43d7-8f08-7367922701e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(535, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x2ac_EMHVvqr"
      },
      "outputs": [],
      "source": [
        "# loop over each of the unique zip codes and their corresponding\n",
        "# count\n",
        "for (zipcode, count) in zip(zipcodes, counts):\n",
        "    # the zip code counts for our housing dataset is *extremely*\n",
        "    # unbalanced (some only having 1 or 2 houses per zip code)\n",
        "    # so let's sanitize our data by removing any houses with less\n",
        "    # than 25 houses per zip code\n",
        "    if count < 25:\n",
        "        idxs = df[df[\"zipcode\"] == zipcode].index\n",
        "        df.drop(idxs, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxcSBegDVvqs",
        "outputId": "6f6a177c-8f5a-4e4c-e076-3fd63bd988d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(362, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L98kpmW4Vvqs",
        "outputId": "730dc84d-38f0-4b5a-8a18-4206ec60ebbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(271, 5)\n",
            "(91, 5)\n"
          ]
        }
      ],
      "source": [
        "(train, test) = train_test_split(df, test_size=0.25, random_state=42)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rThHpNarVvqs"
      },
      "source": [
        "## Preprocessing\n",
        "Sacel every col to [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4eS5I8FiVvqt"
      },
      "outputs": [],
      "source": [
        "# find the largest house price in the training set and use it to\n",
        "# scale our house prices to the range [0, 1] (this will lead to\n",
        "# better training and convergence)\n",
        "maxPrice = train[\"price\"].max()\n",
        "trainY = train[\"price\"] / maxPrice\n",
        "testY = test[\"price\"] / maxPrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zkXMFbSxVvqt"
      },
      "outputs": [],
      "source": [
        "# initialize the column names of the continuous data\n",
        "continuous = [\"bedrooms\", \"bathrooms\", \"area\"]\n",
        "\n",
        "# performin min-max scaling each continuous feature column to\n",
        "# the range [0, 1]\n",
        "# It scales the features in a way that their values lie between a given minimum and maximum value, typically between 0 and 1.\n",
        "cs = MinMaxScaler()\n",
        "\n",
        "# The fit() part calculates the minimum and maximum value for each feature, and the transform() part scales the features.\n",
        "trainContinuous = cs.fit_transform(train[continuous])\n",
        "\n",
        "# transform() method is used to scale the test data (test) based on the minimum and maximum values calculated from the training data.\n",
        "testContinuous = cs.transform(test[continuous])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainContinuous[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ZtJeCqZItl",
        "outputId": "2c4076d9-5b6d-49b7-a8a5-400bed80be12"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.44444444, 0.45454545, 0.56262899])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"zipcode\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voD9xzmrZaB4",
        "outputId": "7157e9d4-68f4-4dff-fafe-8e883fc885af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([93446, 91901, 92677, 94501, 92880, 92276, 93510])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_practice = df[\"zipcode\"]\n",
        "df_practice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHyciecuaFKN",
        "outputId": "7b5f4038-1b8e-4b50-e3ba-1a7d84f5b4dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30     93446\n",
              "32     93446\n",
              "39     93446\n",
              "80     91901\n",
              "81     91901\n",
              "       ...  \n",
              "499    93446\n",
              "500    93446\n",
              "501    93446\n",
              "502    93446\n",
              "503    93446\n",
              "Name: zipcode, Length: 362, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement one-hot encoding\n",
        "\n",
        "# First\n",
        "lb = LabelBinarizer()\n",
        "# calcualte the unique values\n",
        "unique_values = lb.fit(df_practice)\n",
        "# perform the one-hot based on the unique values\n",
        "new_df = unique_values.transform(df_practice)\n",
        "print(type(new_df))\n",
        "new_df\n",
        "\n",
        "# Second\n",
        "# pd.get_dummies(df, columns=['Fruit'])\n",
        "new_df = pd.get_dummies(df_practice)\n",
        "print(type(new_df))\n",
        "new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "ibLdxzCIaMZ1",
        "outputId": "4e22fcf2-1ced-4709-b2b5-7bf62effa37d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     91901  92276  92677  92880  93446  93510  94501\n",
              "30       0      0      0      0      1      0      0\n",
              "32       0      0      0      0      1      0      0\n",
              "39       0      0      0      0      1      0      0\n",
              "80       1      0      0      0      0      0      0\n",
              "81       1      0      0      0      0      0      0\n",
              "..     ...    ...    ...    ...    ...    ...    ...\n",
              "499      0      0      0      0      1      0      0\n",
              "500      0      0      0      0      1      0      0\n",
              "501      0      0      0      0      1      0      0\n",
              "502      0      0      0      0      1      0      0\n",
              "503      0      0      0      0      1      0      0\n",
              "\n",
              "[362 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e649d87-ee05-464f-b65c-c6bb0a84de42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>91901</th>\n",
              "      <th>92276</th>\n",
              "      <th>92677</th>\n",
              "      <th>92880</th>\n",
              "      <th>93446</th>\n",
              "      <th>93510</th>\n",
              "      <th>94501</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>362 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e649d87-ee05-464f-b65c-c6bb0a84de42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e649d87-ee05-464f-b65c-c6bb0a84de42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e649d87-ee05-464f-b65c-c6bb0a84de42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9e997b8-759c-43b8-a8e7-cae0b4218b3e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9e997b8-759c-43b8-a8e7-cae0b4218b3e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9e997b8-759c-43b8-a8e7-cae0b4218b3e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Fsx2Zc8EVvqu"
      },
      "outputs": [],
      "source": [
        "# one-hot encode the zip code categorical data (by definition of\n",
        "# one-hot encoing, all output features are now in the range [0, 1])\n",
        "zipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\n",
        "trainCategorical = zipBinarizer.transform(train[\"zipcode\"])\n",
        "testCategorical = zipBinarizer.transform(test[\"zipcode\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ith8IcOzVvqv",
        "outputId": "e9c65780-8c46-4ffd-db5c-1ceb28e5aa02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(271, 10)\n",
            "(91, 10)\n"
          ]
        }
      ],
      "source": [
        "# construct our training and testing data points by concatenating\n",
        "# the categorical features with the continuous features\n",
        "trainX = np.hstack([trainCategorical, trainContinuous])\n",
        "testX = np.hstack([testCategorical, testContinuous])\n",
        "\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSveZq9hVvqv"
      },
      "source": [
        "## Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "geKtoslnVvqw"
      },
      "outputs": [],
      "source": [
        "dim = trainX.shape[1]\n",
        "# define our MLP network\n",
        "model=None\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
        "model.add(Dense(4, activation=\"relu\"))\n",
        "# for regression the last actvation function is linear === no action\n",
        "model.add(Dense(1, activation=\"linear\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYuPb2uGVvqw"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">Compile model</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mbb-gSSoVvqw"
      },
      "outputs": [],
      "source": [
        "# opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "opt = Adam(learning_rate=1e-3)\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    decay_rate = 1e-3 / 200\n",
        "    return lr * (1 / (1 + decay_rate * epoch))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jckc-ONUVvqx",
        "outputId": "0cb5be91-1b67-4f1b-9e03-2eddc3a0e76e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 9s 15ms/step - loss: 170.0555 - val_loss: 83.8825 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 62.2991 - val_loss: 55.3627 - lr: 1.0000e-03\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 46.2062 - val_loss: 47.9011 - lr: 9.9999e-04\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 42.5387 - val_loss: 43.1980 - lr: 9.9997e-04\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 39.7969 - val_loss: 37.8295 - lr: 9.9995e-04\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 35.8851 - val_loss: 31.3678 - lr: 9.9992e-04\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 30.6584 - val_loss: 26.6754 - lr: 9.9989e-04\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 27.0406 - val_loss: 23.5597 - lr: 9.9986e-04\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 26.2078 - val_loss: 25.6229 - lr: 9.9982e-04\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 26.5774 - val_loss: 23.3916 - lr: 9.9977e-04\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 27.0521 - val_loss: 23.1380 - lr: 9.9972e-04\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 24.8803 - val_loss: 23.7022 - lr: 9.9967e-04\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 24.2196 - val_loss: 23.1595 - lr: 9.9961e-04\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 24.6526 - val_loss: 22.0635 - lr: 9.9955e-04\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 24.3644 - val_loss: 22.2645 - lr: 9.9948e-04\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 24.5599 - val_loss: 22.0235 - lr: 9.9940e-04\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 23.6800 - val_loss: 22.2087 - lr: 9.9932e-04\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 23.3985 - val_loss: 21.6220 - lr: 9.9924e-04\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 23.1057 - val_loss: 21.9030 - lr: 9.9915e-04\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 23.1551 - val_loss: 21.8720 - lr: 9.9905e-04\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 23.0649 - val_loss: 21.6510 - lr: 9.9895e-04\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 23.3442 - val_loss: 22.3469 - lr: 9.9885e-04\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 23.8498 - val_loss: 22.9708 - lr: 9.9874e-04\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 23.0881 - val_loss: 21.7903 - lr: 9.9862e-04\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 22.4831 - val_loss: 22.2919 - lr: 9.9850e-04\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 22.4694 - val_loss: 21.9365 - lr: 9.9838e-04\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 23.8965 - val_loss: 21.4999 - lr: 9.9825e-04\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 22.6206 - val_loss: 23.3124 - lr: 9.9811e-04\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 23.2303 - val_loss: 21.7460 - lr: 9.9797e-04\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 22.3847 - val_loss: 22.3000 - lr: 9.9783e-04\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 21.9418 - val_loss: 21.3209 - lr: 9.9768e-04\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 22.5247 - val_loss: 21.1870 - lr: 9.9752e-04\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 21.8931 - val_loss: 22.0090 - lr: 9.9736e-04\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 21.9996 - val_loss: 21.4477 - lr: 9.9720e-04\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 23.3540 - val_loss: 20.8603 - lr: 9.9703e-04\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 21.6864 - val_loss: 20.8662 - lr: 9.9686e-04\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 22.3386 - val_loss: 21.0053 - lr: 9.9668e-04\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 21.6984 - val_loss: 21.1475 - lr: 9.9649e-04\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 21.5252 - val_loss: 22.5120 - lr: 9.9630e-04\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 22.6052 - val_loss: 21.8641 - lr: 9.9611e-04\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 22.4434 - val_loss: 22.0504 - lr: 9.9591e-04\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 22.5758 - val_loss: 21.2966 - lr: 9.9570e-04\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 22.0815 - val_loss: 20.8003 - lr: 9.9550e-04\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 22.1337 - val_loss: 22.7618 - lr: 9.9528e-04\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 22.3643 - val_loss: 22.7121 - lr: 9.9506e-04\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 22.7720 - val_loss: 20.4050 - lr: 9.9484e-04\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 22.5134 - val_loss: 20.3156 - lr: 9.9461e-04\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 21.5484 - val_loss: 26.2107 - lr: 9.9438e-04\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 22.8778 - val_loss: 24.2063 - lr: 9.9414e-04\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 22.1025 - val_loss: 22.2108 - lr: 9.9389e-04\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 20.3981 - val_loss: 20.8622 - lr: 9.9365e-04\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 21.9082 - val_loss: 22.2630 - lr: 9.9339e-04\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 21.3304 - val_loss: 21.0643 - lr: 9.9313e-04\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 21.3213 - val_loss: 21.1677 - lr: 9.9287e-04\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 21.1966 - val_loss: 21.4433 - lr: 9.9260e-04\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.8200 - val_loss: 22.0475 - lr: 9.9233e-04\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 21.5876 - val_loss: 21.1852 - lr: 9.9205e-04\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.5105 - val_loss: 23.5273 - lr: 9.9177e-04\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 21.1432 - val_loss: 21.4996 - lr: 9.9148e-04\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 20.7313 - val_loss: 21.7218 - lr: 9.9119e-04\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.1748 - val_loss: 21.1894 - lr: 9.9089e-04\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.3130 - val_loss: 23.5631 - lr: 9.9059e-04\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.9020 - val_loss: 20.7101 - lr: 9.9028e-04\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 21.3034 - val_loss: 22.0769 - lr: 9.8997e-04\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.1258 - val_loss: 22.4771 - lr: 9.8966e-04\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.4371 - val_loss: 20.6348 - lr: 9.8933e-04\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.9316 - val_loss: 21.6352 - lr: 9.8901e-04\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.1975 - val_loss: 21.9536 - lr: 9.8868e-04\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.2815 - val_loss: 23.7346 - lr: 9.8834e-04\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 22.6671 - val_loss: 22.4804 - lr: 9.8800e-04\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 21.7038 - val_loss: 21.6897 - lr: 9.8765e-04\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.6594 - val_loss: 22.1923 - lr: 9.8730e-04\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.6666 - val_loss: 22.3586 - lr: 9.8695e-04\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 21.4054 - val_loss: 23.4096 - lr: 9.8659e-04\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 22.2188 - val_loss: 21.5704 - lr: 9.8622e-04\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.4232 - val_loss: 22.1334 - lr: 9.8585e-04\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.4602 - val_loss: 21.7528 - lr: 9.8548e-04\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.7766 - val_loss: 24.6133 - lr: 9.8510e-04\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.7179 - val_loss: 22.0501 - lr: 9.8471e-04\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.3808 - val_loss: 26.4352 - lr: 9.8433e-04\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.7978 - val_loss: 22.9457 - lr: 9.8393e-04\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.0067 - val_loss: 24.3398 - lr: 9.8353e-04\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.4779 - val_loss: 24.2274 - lr: 9.8313e-04\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.5866 - val_loss: 23.0215 - lr: 9.8272e-04\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.1057 - val_loss: 24.0047 - lr: 9.8231e-04\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.6919 - val_loss: 23.0260 - lr: 9.8189e-04\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.5060 - val_loss: 22.8890 - lr: 9.8147e-04\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 21.5740 - val_loss: 23.8001 - lr: 9.8104e-04\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.8386 - val_loss: 22.7798 - lr: 9.8061e-04\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 21.2096 - val_loss: 24.7133 - lr: 9.8018e-04\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.9247 - val_loss: 22.7285 - lr: 9.7974e-04\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.8247 - val_loss: 22.3003 - lr: 9.7929e-04\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.3328 - val_loss: 25.5850 - lr: 9.7884e-04\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1747 - val_loss: 21.8048 - lr: 9.7839e-04\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1282 - val_loss: 22.4616 - lr: 9.7793e-04\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.0489 - val_loss: 22.4841 - lr: 9.7746e-04\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.9878 - val_loss: 25.4927 - lr: 9.7699e-04\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1642 - val_loss: 25.5511 - lr: 9.7652e-04\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1924 - val_loss: 21.8172 - lr: 9.7604e-04\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.4886 - val_loss: 22.2488 - lr: 9.7556e-04\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.0087 - val_loss: 21.7549 - lr: 9.7507e-04\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.3334 - val_loss: 24.7138 - lr: 9.7458e-04\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.1470 - val_loss: 22.3040 - lr: 9.7408e-04\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.4311 - val_loss: 21.6701 - lr: 9.7358e-04\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.3627 - val_loss: 24.4783 - lr: 9.7307e-04\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.7025 - val_loss: 22.4563 - lr: 9.7256e-04\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.0045 - val_loss: 23.6780 - lr: 9.7205e-04\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.8325 - val_loss: 22.2362 - lr: 9.7153e-04\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.7973 - val_loss: 22.4197 - lr: 9.7100e-04\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1087 - val_loss: 23.2280 - lr: 9.7048e-04\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.4940 - val_loss: 23.4258 - lr: 9.6994e-04\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.1586 - val_loss: 22.6393 - lr: 9.6940e-04\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.4974 - val_loss: 23.5236 - lr: 9.6886e-04\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 20.7262 - val_loss: 24.1688 - lr: 9.6831e-04\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 20.0348 - val_loss: 25.3071 - lr: 9.6776e-04\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.9794 - val_loss: 23.0258 - lr: 9.6721e-04\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 20.1497 - val_loss: 23.1912 - lr: 9.6665e-04\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.8053 - val_loss: 23.2157 - lr: 9.6608e-04\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.8896 - val_loss: 22.4689 - lr: 9.6551e-04\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 19.9457 - val_loss: 21.7329 - lr: 9.6494e-04\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.8131 - val_loss: 21.9858 - lr: 9.6436e-04\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 21.4826 - val_loss: 21.7602 - lr: 9.6377e-04\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 20.6042 - val_loss: 26.0831 - lr: 9.6319e-04\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.9102 - val_loss: 23.5573 - lr: 9.6260e-04\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.5751 - val_loss: 22.7311 - lr: 9.6200e-04\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.2891 - val_loss: 22.4186 - lr: 9.6140e-04\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.9111 - val_loss: 24.5826 - lr: 9.6079e-04\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.4372 - val_loss: 22.4787 - lr: 9.6018e-04\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.2632 - val_loss: 22.1151 - lr: 9.5957e-04\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.9904 - val_loss: 22.6215 - lr: 9.5895e-04\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8580 - val_loss: 22.5966 - lr: 9.5833e-04\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1920 - val_loss: 23.7235 - lr: 9.5770e-04\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.6780 - val_loss: 26.5290 - lr: 9.5707e-04\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.2672 - val_loss: 24.7893 - lr: 9.5643e-04\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.4419 - val_loss: 22.2656 - lr: 9.5579e-04\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.0078 - val_loss: 23.0253 - lr: 9.5515e-04\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 19.9051 - val_loss: 22.4572 - lr: 9.5450e-04\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.0200 - val_loss: 22.4961 - lr: 9.5384e-04\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.9804 - val_loss: 22.2957 - lr: 9.5319e-04\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8235 - val_loss: 22.4984 - lr: 9.5253e-04\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8585 - val_loss: 22.9553 - lr: 9.5186e-04\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8047 - val_loss: 22.8181 - lr: 9.5119e-04\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.2225 - val_loss: 23.0914 - lr: 9.5051e-04\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.3559 - val_loss: 25.3620 - lr: 9.4983e-04\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1275 - val_loss: 22.3581 - lr: 9.4915e-04\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.0114 - val_loss: 22.8202 - lr: 9.4846e-04\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.0755 - val_loss: 23.9554 - lr: 9.4777e-04\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.3547 - val_loss: 23.1342 - lr: 9.4708e-04\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1680 - val_loss: 22.5165 - lr: 9.4637e-04\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.6398 - val_loss: 23.2210 - lr: 9.4567e-04\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8347 - val_loss: 22.3586 - lr: 9.4496e-04\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.5518 - val_loss: 22.1246 - lr: 9.4425e-04\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.0153 - val_loss: 22.9079 - lr: 9.4353e-04\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1582 - val_loss: 22.4671 - lr: 9.4281e-04\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.3341 - val_loss: 22.1733 - lr: 9.4208e-04\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.3686 - val_loss: 24.0157 - lr: 9.4136e-04\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8192 - val_loss: 25.0032 - lr: 9.4062e-04\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 19.7829 - val_loss: 23.3754 - lr: 9.3988e-04\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.2684 - val_loss: 21.7459 - lr: 9.3914e-04\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 19.7902 - val_loss: 24.0776 - lr: 9.3840e-04\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1846 - val_loss: 23.9649 - lr: 9.3765e-04\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 19.7726 - val_loss: 24.6295 - lr: 9.3689e-04\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1276 - val_loss: 22.7091 - lr: 9.3613e-04\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.3545 - val_loss: 23.9020 - lr: 9.3537e-04\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.9479 - val_loss: 22.2709 - lr: 9.3460e-04\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.5824 - val_loss: 22.2752 - lr: 9.3383e-04\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.9327 - val_loss: 21.9737 - lr: 9.3306e-04\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.2715 - val_loss: 22.6905 - lr: 9.3228e-04\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 19.0470 - val_loss: 24.5886 - lr: 9.3150e-04\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.1148 - val_loss: 22.7711 - lr: 9.3071e-04\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.6067 - val_loss: 22.6845 - lr: 9.2992e-04\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.6504 - val_loss: 21.9068 - lr: 9.2913e-04\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 21.2104 - val_loss: 22.2987 - lr: 9.2833e-04\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8490 - val_loss: 22.7009 - lr: 9.2753e-04\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.7804 - val_loss: 23.0412 - lr: 9.2672e-04\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.1175 - val_loss: 22.5611 - lr: 9.2591e-04\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.4540 - val_loss: 21.8393 - lr: 9.2510e-04\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.6640 - val_loss: 24.3847 - lr: 9.2428e-04\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.4503 - val_loss: 22.2744 - lr: 9.2346e-04\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8550 - val_loss: 23.4458 - lr: 9.2263e-04\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.6324 - val_loss: 23.5882 - lr: 9.2180e-04\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.5413 - val_loss: 22.1645 - lr: 9.2097e-04\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.2846 - val_loss: 22.3172 - lr: 9.2013e-04\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.3330 - val_loss: 24.2889 - lr: 9.1929e-04\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.8609 - val_loss: 22.4255 - lr: 9.1844e-04\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 20.0185 - val_loss: 23.3006 - lr: 9.1760e-04\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 20.7247 - val_loss: 23.0275 - lr: 9.1674e-04\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 19.7979 - val_loss: 23.0789 - lr: 9.1589e-04\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.4327 - val_loss: 22.1549 - lr: 9.1503e-04\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.8907 - val_loss: 21.0517 - lr: 9.1416e-04\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 20.7466 - val_loss: 24.5358 - lr: 9.1329e-04\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.6328 - val_loss: 21.1891 - lr: 9.1242e-04\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.5058 - val_loss: 22.8490 - lr: 9.1155e-04\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.7232 - val_loss: 22.0978 - lr: 9.1067e-04\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 19.4688 - val_loss: 22.0252 - lr: 9.0979e-04\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 19.6702 - val_loss: 23.8594 - lr: 9.0890e-04\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 19.6868 - val_loss: 20.8234 - lr: 9.0801e-04\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 20.2602 - val_loss: 22.9548 - lr: 9.0712e-04\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 20.4422 - val_loss: 21.8221 - lr: 9.0622e-04\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 19.4160 - val_loss: 23.0924 - lr: 9.0532e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c8340143b20>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY),\n",
        "    epochs=200, batch_size=8, callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testX, testY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLcA1NRrfnqN",
        "outputId": "fcd041ea-af32-4dfe-e013-95c5e7ef47d4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 23.0924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.092443466186523"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkGIljawVvqx",
        "outputId": "51e98cc8-7bfe-4377-b4d7-e02d2c8c2caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(testX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V86SWQ_8fO1n",
        "outputId": "cd8dc2e4-d857-432d-bf57-b2d712ee2134"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(91, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testY.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uyo7b2_fSF5",
        "outputId": "a7512da7-97c9-4ea3-be3f-d68d244c70e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(91,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.flatten() - testY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En_LM3JjfU4l",
        "outputId": "9e44422b-6a5d-491d-d677-9e263eec9666"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305   -0.005163\n",
              "110    0.025632\n",
              "92    -0.055330\n",
              "464   -0.041585\n",
              "145    0.007235\n",
              "         ...   \n",
              "458   -0.028004\n",
              "452   -0.007563\n",
              "481   -0.020857\n",
              "232   -0.022699\n",
              "437   -0.000738\n",
              "Name: price, Length: 91, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unvzjq0bVvqy",
        "outputId": "5903b359-bb92-4733-a1f8-65f6534d13d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step\n",
            "avg. house price: $533,388.27, std house price: $493,403.08\n",
            "mean: 23.09%, std: 18.69%\n"
          ]
        }
      ],
      "source": [
        "# make predictions on the testing data\n",
        "preds = model.predict(testX)\n",
        "\n",
        "# compute the difference between the *predicted* house prices and the\n",
        "# *actual* house prices, then compute the percentage difference and\n",
        "# the absolute percentage difference\n",
        "diff = preds.flatten() - testY\n",
        "percentDiff = (diff / testY) * 100\n",
        "absPercentDiff = np.abs(percentDiff)\n",
        "\n",
        "# compute the mean and standard deviation of the absolute percentage\n",
        "# difference\n",
        "mean = np.mean(absPercentDiff)\n",
        "std = np.std(absPercentDiff)\n",
        "\n",
        "# finally, show some statistics on our model\n",
        "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
        "print(\"avg. house price: {}, std house price: {}\".format(\n",
        "    locale.currency(df[\"price\"].mean(), grouping=True),\n",
        "    locale.currency(df[\"price\"].std(), grouping=True)))\n",
        "print(\"mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "predictions = model.predict(testX)\n",
        "mse = mean_squared_error(testY, predictions)\n",
        "mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df_mbZhVgBGJ",
        "outputId": "d0a5ad84-c3e8-489e-e3c7-bace11134fcf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0010155557681256584"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional API\n",
        "\n",
        "When the network is divided into two separate sections, for example we have numbers and images both as an input, we need to use the functional API coding based on the keras to be able to join the different parts of the network together.  \n",
        "Also, we can have two outputs in the network rather than only the one last output.\n"
      ],
      "metadata": {
        "id": "nXccfuGpgio_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "r9ErTribu23K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "0e92d752-718e-40bc-cd46-80ab8cc2301b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     bedrooms  bathrooms  area  zipcode    price\n",
              "30          5        3.0  2520    93446   789000\n",
              "32          3        2.0  1802    93446   365000\n",
              "39          3        3.0  2146    93446   455000\n",
              "80          4        2.5  2464    91901   599000\n",
              "81          2        2.0  1845    91901   529800\n",
              "..        ...        ...   ...      ...      ...\n",
              "499         4        4.0  3000    93446  1495000\n",
              "500         3        2.0  2330    93446   599900\n",
              "501         3        2.5  1339    93446   344900\n",
              "502         3        2.0  1472    93446   309995\n",
              "503         4        4.0  2681    93446   572000\n",
              "\n",
              "[362 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79647284-eece-4e9e-af6a-e327d7b9d2b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>area</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2520</td>\n",
              "      <td>93446</td>\n",
              "      <td>789000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1802</td>\n",
              "      <td>93446</td>\n",
              "      <td>365000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2146</td>\n",
              "      <td>93446</td>\n",
              "      <td>455000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>4</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2464</td>\n",
              "      <td>91901</td>\n",
              "      <td>599000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1845</td>\n",
              "      <td>91901</td>\n",
              "      <td>529800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3000</td>\n",
              "      <td>93446</td>\n",
              "      <td>1495000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2330</td>\n",
              "      <td>93446</td>\n",
              "      <td>599900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1339</td>\n",
              "      <td>93446</td>\n",
              "      <td>344900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1472</td>\n",
              "      <td>93446</td>\n",
              "      <td>309995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2681</td>\n",
              "      <td>93446</td>\n",
              "      <td>572000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>362 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79647284-eece-4e9e-af6a-e327d7b9d2b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79647284-eece-4e9e-af6a-e327d7b9d2b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79647284-eece-4e9e-af6a-e327d7b9d2b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1d634244-9df1-413d-8673-7b51086cc16a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d634244-9df1-413d-8673-7b51086cc16a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1d634244-9df1-413d-8673-7b51086cc16a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"zipcode\"] < 25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rEMS3zcxvJ2h",
        "outputId": "c0204483-8fe2-44d8-e4a9-416eb040c385"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [bedrooms, bathrooms, area, zipcode, price]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aada8f4c-e3b4-4f13-b5d5-ad19cb22afa8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>area</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aada8f4c-e3b4-4f13-b5d5-ad19cb22afa8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aada8f4c-e3b4-4f13-b5d5-ad19cb22afa8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aada8f4c-e3b4-4f13-b5d5-ad19cb22afa8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 362 houses > 4 image peer house\n",
        "datasetPath = \"Houses Dataset\"\n",
        "basePath = os.path.sep.join([datasetPath, \"1_*\"])\n",
        "print(basePath)\n",
        "sorted(list(glob.glob(basePath)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL03IuzSvllG",
        "outputId": "2c3904dd-c4c0-4e1d-e1d8-d14d469322ed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Houses Dataset/1_*\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Houses Dataset/1_bathroom.jpg',\n",
              " 'Houses Dataset/1_bedroom.jpg',\n",
              " 'Houses Dataset/1_frontal.jpg',\n",
              " 'Houses Dataset/1_kitchen.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize our images array (i.e., the house images themselves)\n",
        "images = []\n",
        "\n",
        "# loop over the indexes of the houses\n",
        "for i in df.index.values:\n",
        "    # find the four images for the house and sort the file paths,\n",
        "    # ensuring the four are always in the *same order*\n",
        "    basePath = os.path.sep.join([datasetPath, \"{}_*\".format(i + 1)])\n",
        "    housePaths = sorted(list(glob.glob(basePath)))\n",
        "    # initialize our list of input images along with the output image\n",
        "    # after *combining* the four input images\n",
        "    inputImages = []\n",
        "    outputImage = np.zeros((64, 64, 3), dtype=\"uint8\")\n",
        "\n",
        "    # loop over the input house paths\n",
        "    for housePath in housePaths:\n",
        "        # load the input image, resize it to be 32 32, and then\n",
        "        # update the list of input images\n",
        "        image = cv2.imread(housePath)\n",
        "        image = cv2.resize(image, (32, 32))\n",
        "        inputImages.append(image)\n",
        "\n",
        "    # tile the four input images in the output image such the first\n",
        "    # image goes in the top-right corner, the second image in the\n",
        "    # top-left corner, the third image in the bottom-right corner,\n",
        "    # and the final image in the bottom-left corner\n",
        "    outputImage[0:32, 0:32] = inputImages[0]\n",
        "    outputImage[0:32, 32:64] = inputImages[1]\n",
        "    outputImage[32:64, 32:64] = inputImages[2]\n",
        "    outputImage[32:64, 0:32] = inputImages[3]\n",
        "\n",
        "    # add the tiled image to our set of images the network will be\n",
        "    # trained on\n",
        "    images.append(outputImage)\n",
        "images = np.array(images)"
      ],
      "metadata": {
        "id": "eHgExY0PgEQi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knN7a93ywTPl",
        "outputId": "036eb946-32fb-4129-cb7b-2b7ca8fd7d8d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(362, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[37][...,::-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "_UKt0-HbwTjI",
        "outputId": "27540c6d-6ba8-4e19-961a-43d758a28846"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c82d45be290>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = images / 255.0"
      ],
      "metadata": {
        "id": "dPe-piX4xYZ1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "split = train_test_split(df, images, test_size=0.25, random_state=42)\n",
        "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split"
      ],
      "metadata": {
        "id": "Jp1WTK-2xXxh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the largest house price in the training set and use it to\n",
        "# scale our house prices to the range [0, 1] (will lead to better\n",
        "# training and convergence)\n",
        "maxPrice = trainAttrX[\"price\"].max()\n",
        "trainY = trainAttrX[\"price\"] / maxPrice\n",
        "testY = testAttrX[\"price\"] / maxPrice"
      ],
      "metadata": {
        "id": "slOAVSABw0Df"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=None"
      ],
      "metadata": {
        "id": "5VIaaiNDBcZf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "width, height, depth = 64, 64, 3\n",
        "filters=(16, 32, 64)\n",
        "# initialize the input shape and channel dimension, assuming\n",
        "# TensorFlow/channels-last ordering\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "\n",
        "# define the model input\n",
        "inputs = Input(shape=inputShape)\n",
        "\n",
        "# loop over the number of filters\n",
        "for (i, f) in enumerate(filters):\n",
        "    # if this is the first CONV layer then set the input\n",
        "    # appropriately\n",
        "    if i == 0:\n",
        "        x = inputs\n",
        "\n",
        "    # CONV => RELU => BN => POOL\n",
        "    x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# flatten the volume, then FC => RELU => BN => DROPOUT\n",
        "x = Flatten()(x)\n",
        "x = Dense(16)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# apply another FC layer, this one to match the number of nodes\n",
        "# coming out of the MLP\n",
        "x = Dense(4)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "x = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "# construct the CNN\n",
        "model = Model(inputs, x)"
      ],
      "metadata": {
        "id": "CGsR9_tCybql"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds8K8YmszZUC",
        "outputId": "4ac32610-3486-4de8-8f04-78c946ba7b7b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 64, 64, 16)        448       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 16)        0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 64, 64, 16)        64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 32, 32, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                65552     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16)                64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89721 (350.47 KB)\n",
            "Trainable params: 89465 (349.47 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "opt = Adam(learning_rate=1e-3)\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    decay_rate = 1e-3 / 200\n",
        "    return lr * (1 / (1 + decay_rate * epoch))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
      ],
      "metadata": {
        "id": "InxYzUSu0AaM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainImagesX, trainY, validation_data=(testImagesX, testY),\n",
        "          epochs=200, batch_size=8, callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbIhWL-y0JQS",
        "outputId": "ed2f5a72-fc2e-42e8-d7e9-44c8b89bbc74"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 1072.5166 - val_loss: 310.9883 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 684.3867 - val_loss: 511.2831 - lr: 1.0000e-03\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 591.5347 - val_loss: 494.4529 - lr: 9.9999e-04\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 390.8344 - val_loss: 873.2717 - lr: 9.9997e-04\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 357.0890 - val_loss: 1308.2455 - lr: 9.9995e-04\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 268.3344 - val_loss: 1812.2729 - lr: 9.9992e-04\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 275.1304 - val_loss: 2518.5366 - lr: 9.9989e-04\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 242.1541 - val_loss: 3656.9028 - lr: 9.9986e-04\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 194.9352 - val_loss: 4551.2070 - lr: 9.9982e-04\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 196.3720 - val_loss: 5372.0098 - lr: 9.9977e-04\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 147.8324 - val_loss: 7735.3384 - lr: 9.9972e-04\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 124.5187 - val_loss: 6703.9019 - lr: 9.9967e-04\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 126.9841 - val_loss: 4589.9585 - lr: 9.9961e-04\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 118.0068 - val_loss: 1881.3311 - lr: 9.9955e-04\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 108.2299 - val_loss: 1350.0323 - lr: 9.9948e-04\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 93.7901 - val_loss: 387.4897 - lr: 9.9940e-04\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 99.7511 - val_loss: 179.0418 - lr: 9.9932e-04\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 89.4846 - val_loss: 68.3479 - lr: 9.9924e-04\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 89.1591 - val_loss: 69.2450 - lr: 9.9915e-04\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 98.5565 - val_loss: 63.6939 - lr: 9.9905e-04\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 86.2067 - val_loss: 72.2169 - lr: 9.9895e-04\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 81.2090 - val_loss: 68.4585 - lr: 9.9885e-04\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 73.5928 - val_loss: 69.1102 - lr: 9.9874e-04\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 70.7503 - val_loss: 74.2516 - lr: 9.9862e-04\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 69.7690 - val_loss: 74.6003 - lr: 9.9850e-04\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 70.4816 - val_loss: 75.8768 - lr: 9.9838e-04\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 72.2994 - val_loss: 66.4218 - lr: 9.9825e-04\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 70.6352 - val_loss: 70.5840 - lr: 9.9811e-04\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 67.2557 - val_loss: 71.4942 - lr: 9.9797e-04\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 75.5113 - val_loss: 66.7238 - lr: 9.9783e-04\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 72.5825 - val_loss: 81.3792 - lr: 9.9768e-04\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 64.2490 - val_loss: 75.3838 - lr: 9.9752e-04\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 64.4282 - val_loss: 73.9999 - lr: 9.9736e-04\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 65.5502 - val_loss: 74.8688 - lr: 9.9720e-04\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 62.0583 - val_loss: 68.6136 - lr: 9.9703e-04\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 61.4347 - val_loss: 69.6122 - lr: 9.9686e-04\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 62.8295 - val_loss: 77.3735 - lr: 9.9668e-04\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 58.7939 - val_loss: 69.4794 - lr: 9.9649e-04\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 65.1017 - val_loss: 71.4421 - lr: 9.9630e-04\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 62.6684 - val_loss: 63.0115 - lr: 9.9611e-04\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 60.9869 - val_loss: 333.3440 - lr: 9.9591e-04\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 63.1966 - val_loss: 172.1800 - lr: 9.9570e-04\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 63.1399 - val_loss: 95.3682 - lr: 9.9550e-04\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 73.4431 - val_loss: 66.4496 - lr: 9.9528e-04\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 64.6964 - val_loss: 64.3980 - lr: 9.9506e-04\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 67.2867 - val_loss: 65.7004 - lr: 9.9484e-04\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 58.5524 - val_loss: 63.5688 - lr: 9.9461e-04\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 65.3419 - val_loss: 64.1828 - lr: 9.9438e-04\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 60.8835 - val_loss: 65.7809 - lr: 9.9414e-04\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 58.3981 - val_loss: 66.6850 - lr: 9.9389e-04\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 56.0523 - val_loss: 65.5280 - lr: 9.9365e-04\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 55.6787 - val_loss: 64.5707 - lr: 9.9339e-04\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 60.3220 - val_loss: 64.9092 - lr: 9.9313e-04\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 60.4759 - val_loss: 63.8622 - lr: 9.9287e-04\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 62.6416 - val_loss: 61.1927 - lr: 9.9260e-04\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 58.7467 - val_loss: 61.7852 - lr: 9.9233e-04\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 59.2148 - val_loss: 61.2964 - lr: 9.9205e-04\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 56.7967 - val_loss: 63.1162 - lr: 9.9177e-04\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 56.6011 - val_loss: 65.4196 - lr: 9.9148e-04\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 57.5694 - val_loss: 63.5867 - lr: 9.9119e-04\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 54.2787 - val_loss: 63.7479 - lr: 9.9089e-04\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 54.9656 - val_loss: 64.3967 - lr: 9.9059e-04\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 54.6541 - val_loss: 64.8138 - lr: 9.9028e-04\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 52.9370 - val_loss: 63.8525 - lr: 9.8997e-04\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 56.6294 - val_loss: 62.6404 - lr: 9.8966e-04\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 57.1461 - val_loss: 62.7460 - lr: 9.8933e-04\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 55.2948 - val_loss: 62.3830 - lr: 9.8901e-04\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 53.3549 - val_loss: 61.5182 - lr: 9.8868e-04\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 50.9484 - val_loss: 60.5483 - lr: 9.8834e-04\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 55.1758 - val_loss: 60.7497 - lr: 9.8800e-04\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 51.7891 - val_loss: 63.3673 - lr: 9.8765e-04\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 52.8846 - val_loss: 64.3817 - lr: 9.8730e-04\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 49.9396 - val_loss: 66.6212 - lr: 9.8695e-04\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 51.5158 - val_loss: 61.5504 - lr: 9.8659e-04\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 54.6713 - val_loss: 60.5379 - lr: 9.8622e-04\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 52.6399 - val_loss: 59.4195 - lr: 9.8585e-04\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 56.9330 - val_loss: 60.6742 - lr: 9.8548e-04\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 49.7589 - val_loss: 61.5667 - lr: 9.8510e-04\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 47.1144 - val_loss: 59.1722 - lr: 9.8471e-04\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 50.0741 - val_loss: 57.6125 - lr: 9.8433e-04\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 49.6418 - val_loss: 58.7760 - lr: 9.8393e-04\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 51.3359 - val_loss: 60.3037 - lr: 9.8353e-04\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 49.1938 - val_loss: 62.3460 - lr: 9.8313e-04\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 49.9550 - val_loss: 58.7997 - lr: 9.8272e-04\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 49.9951 - val_loss: 59.4608 - lr: 9.8231e-04\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 48.3523 - val_loss: 57.5584 - lr: 9.8189e-04\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 51.3029 - val_loss: 58.3759 - lr: 9.8147e-04\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 46.1915 - val_loss: 57.9163 - lr: 9.8104e-04\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 48.3931 - val_loss: 58.2525 - lr: 9.8061e-04\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 44.8435 - val_loss: 57.7613 - lr: 9.8018e-04\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 48.9466 - val_loss: 59.0864 - lr: 9.7974e-04\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 45.6254 - val_loss: 58.9776 - lr: 9.7929e-04\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 47.6446 - val_loss: 60.8252 - lr: 9.7884e-04\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 49.8215 - val_loss: 58.9629 - lr: 9.7839e-04\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 44.5956 - val_loss: 56.3519 - lr: 9.7793e-04\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 48.0484 - val_loss: 55.8879 - lr: 9.7746e-04\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 44.4693 - val_loss: 60.2705 - lr: 9.7699e-04\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 44.6666 - val_loss: 89.4281 - lr: 9.7652e-04\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 46.7299 - val_loss: 63.5099 - lr: 9.7604e-04\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 42.7644 - val_loss: 60.0443 - lr: 9.7556e-04\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 40.9059 - val_loss: 64.4369 - lr: 9.7507e-04\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 40.8832 - val_loss: 59.3626 - lr: 9.7458e-04\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 46.0811 - val_loss: 57.3926 - lr: 9.7408e-04\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 47.2942 - val_loss: 57.6212 - lr: 9.7358e-04\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 48.8467 - val_loss: 59.1206 - lr: 9.7307e-04\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 45.7248 - val_loss: 58.3185 - lr: 9.7256e-04\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 42.3014 - val_loss: 63.2481 - lr: 9.7205e-04\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 43.5975 - val_loss: 57.0254 - lr: 9.7153e-04\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 39.4290 - val_loss: 56.8996 - lr: 9.7100e-04\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 44.9911 - val_loss: 56.0960 - lr: 9.7048e-04\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 42.1634 - val_loss: 54.3835 - lr: 9.6994e-04\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 44.3349 - val_loss: 55.5463 - lr: 9.6940e-04\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 43.8130 - val_loss: 57.9916 - lr: 9.6886e-04\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 44.2324 - val_loss: 64.9644 - lr: 9.6831e-04\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 41.5111 - val_loss: 58.8275 - lr: 9.6776e-04\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 44.3180 - val_loss: 56.4102 - lr: 9.6721e-04\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 44.9142 - val_loss: 55.0880 - lr: 9.6665e-04\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 42.2975 - val_loss: 58.7585 - lr: 9.6608e-04\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 40.5981 - val_loss: 59.7572 - lr: 9.6551e-04\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 41.7239 - val_loss: 57.3411 - lr: 9.6494e-04\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 46.4102 - val_loss: 55.9554 - lr: 9.6436e-04\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 43.1401 - val_loss: 58.6002 - lr: 9.6377e-04\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 41.1302 - val_loss: 61.9441 - lr: 9.6319e-04\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 41.9049 - val_loss: 60.6936 - lr: 9.6260e-04\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 40.6086 - val_loss: 56.0626 - lr: 9.6200e-04\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 42.5628 - val_loss: 51.4711 - lr: 9.6140e-04\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 40.8154 - val_loss: 56.4296 - lr: 9.6079e-04\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 45.4743 - val_loss: 59.1854 - lr: 9.6018e-04\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 43.1848 - val_loss: 58.4224 - lr: 9.5957e-04\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 41.2403 - val_loss: 64.7443 - lr: 9.5895e-04\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 42.7195 - val_loss: 58.2767 - lr: 9.5833e-04\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 40.0478 - val_loss: 51.2381 - lr: 9.5770e-04\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 45.0904 - val_loss: 50.3191 - lr: 9.5707e-04\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 43.6061 - val_loss: 49.9430 - lr: 9.5643e-04\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 35.7922 - val_loss: 63.7937 - lr: 9.5579e-04\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 40.8516 - val_loss: 52.6371 - lr: 9.5515e-04\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 37.4061 - val_loss: 54.4511 - lr: 9.5450e-04\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 39.4983 - val_loss: 51.5082 - lr: 9.5384e-04\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 40.6541 - val_loss: 51.0088 - lr: 9.5319e-04\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 39.2361 - val_loss: 51.3967 - lr: 9.5253e-04\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 40.0975 - val_loss: 55.9894 - lr: 9.5186e-04\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 37.0966 - val_loss: 49.2073 - lr: 9.5119e-04\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 41.1188 - val_loss: 50.3366 - lr: 9.5051e-04\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 40.6299 - val_loss: 56.4977 - lr: 9.4983e-04\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 38.7717 - val_loss: 52.8032 - lr: 9.4915e-04\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 34.3827 - val_loss: 51.7230 - lr: 9.4846e-04\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 45.5568 - val_loss: 55.7048 - lr: 9.4777e-04\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 38.7281 - val_loss: 63.1393 - lr: 9.4708e-04\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 40.3813 - val_loss: 51.0591 - lr: 9.4637e-04\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 37.2491 - val_loss: 56.1437 - lr: 9.4567e-04\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 39.8167 - val_loss: 48.7000 - lr: 9.4496e-04\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 41.1158 - val_loss: 46.6968 - lr: 9.4425e-04\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 38.2369 - val_loss: 50.0217 - lr: 9.4353e-04\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 35.6330 - val_loss: 64.2140 - lr: 9.4281e-04\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 35.6759 - val_loss: 74.5172 - lr: 9.4208e-04\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 37.1018 - val_loss: 71.2888 - lr: 9.4136e-04\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 35.2481 - val_loss: 49.8960 - lr: 9.4062e-04\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 39.5559 - val_loss: 73.6005 - lr: 9.3988e-04\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 40.0062 - val_loss: 51.7450 - lr: 9.3914e-04\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 36.0019 - val_loss: 49.2966 - lr: 9.3840e-04\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 41.0741 - val_loss: 54.5628 - lr: 9.3765e-04\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 38.3460 - val_loss: 50.6290 - lr: 9.3689e-04\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 40.4359 - val_loss: 51.1095 - lr: 9.3613e-04\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 38.1324 - val_loss: 49.6608 - lr: 9.3537e-04\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 37.4955 - val_loss: 53.4746 - lr: 9.3460e-04\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 35.3897 - val_loss: 58.0515 - lr: 9.3383e-04\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 36.3519 - val_loss: 51.7383 - lr: 9.3306e-04\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 37.2515 - val_loss: 48.4515 - lr: 9.3228e-04\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 39.1113 - val_loss: 66.0343 - lr: 9.3150e-04\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 37.2218 - val_loss: 53.8934 - lr: 9.3071e-04\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 37.4951 - val_loss: 56.9000 - lr: 9.2992e-04\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 34.6607 - val_loss: 57.1847 - lr: 9.2913e-04\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 35.6571 - val_loss: 57.6581 - lr: 9.2833e-04\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 34.8291 - val_loss: 54.2645 - lr: 9.2753e-04\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 36.8548 - val_loss: 50.6322 - lr: 9.2672e-04\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 34.3402 - val_loss: 61.7446 - lr: 9.2591e-04\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 34.2403 - val_loss: 74.5478 - lr: 9.2510e-04\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 40.2633 - val_loss: 84.8746 - lr: 9.2428e-04\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 37.6427 - val_loss: 50.5139 - lr: 9.2346e-04\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 38.7111 - val_loss: 48.9127 - lr: 9.2263e-04\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 34.7487 - val_loss: 47.8917 - lr: 9.2180e-04\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 36.9662 - val_loss: 48.1560 - lr: 9.2097e-04\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 31.7039 - val_loss: 50.7991 - lr: 9.2013e-04\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 38.4674 - val_loss: 48.7268 - lr: 9.1929e-04\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 38.9896 - val_loss: 70.1293 - lr: 9.1844e-04\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 34.6868 - val_loss: 75.7639 - lr: 9.1760e-04\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 37.8006 - val_loss: 49.5153 - lr: 9.1674e-04\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 37.4865 - val_loss: 50.7618 - lr: 9.1589e-04\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 36.7315 - val_loss: 49.5380 - lr: 9.1503e-04\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 34.4217 - val_loss: 51.7569 - lr: 9.1416e-04\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 39.6477 - val_loss: 51.6737 - lr: 9.1329e-04\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 33.8126 - val_loss: 53.3681 - lr: 9.1242e-04\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 37.7018 - val_loss: 50.9047 - lr: 9.1155e-04\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 41.3545 - val_loss: 56.8158 - lr: 9.1067e-04\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 35.5031 - val_loss: 61.5301 - lr: 9.0979e-04\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 38.1964 - val_loss: 64.1372 - lr: 9.0890e-04\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 36.0709 - val_loss: 69.3969 - lr: 9.0801e-04\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 37.1865 - val_loss: 66.2686 - lr: 9.0712e-04\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 36.6970 - val_loss: 57.1184 - lr: 9.0622e-04\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 39.3988 - val_loss: 58.1125 - lr: 9.0532e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c82a7632e30>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testImagesX, testY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYClykn5J4W9",
        "outputId": "42b0c108-67b0-46f9-fb74-e009ad839d23"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 83ms/step - loss: 58.1126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58.112552642822266"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixed Input"
      ],
      "metadata": {
        "id": "yQEC1qWp0g8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We did the normalization for the image and price only\n",
        "\n",
        "continuous = [\"bedrooms\", \"bathrooms\", \"area\"]\n",
        "cs = MinMaxScaler()\n",
        "trainContinuous = cs.fit_transform(trainAttrX[continuous])\n",
        "testContinuous = cs.transform(testAttrX[continuous])\n",
        "\n",
        "zipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\n",
        "trainCategorical = zipBinarizer.transform(trainAttrX[\"zipcode\"])\n",
        "testCategorical = zipBinarizer.transform(testAttrX[\"zipcode\"])\n",
        "\n",
        "trainX = np.hstack([trainCategorical, trainContinuous])\n",
        "testX = np.hstack([testCategorical, testContinuous])"
      ],
      "metadata": {
        "id": "w8YCAOO80giL"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=None"
      ],
      "metadata": {
        "id": "5OX1_qXILkaP"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = trainAttrX.shape[1] #10\n",
        "\n",
        "# define our MLP network\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
        "mlp.add(Dense(4, activation=\"relu\"))"
      ],
      "metadata": {
        "id": "XnncNOWZ7cnr"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "\n",
        "width, height, depth = 64, 64, 3\n",
        "filters=(16, 32, 64)\n",
        "# initialize the input shape and channel dimension, assuming\n",
        "# TensorFlow/channels-last ordering\n",
        "inputShape = (height, width, depth)\n",
        "\n",
        "# define the model input\n",
        "inputs = Input(shape=inputShape)\n",
        "\n",
        "# loop over the number of filters\n",
        "for (i, f) in enumerate(filters):\n",
        "    # if this is the first CONV layer then set the input\n",
        "    # appropriately\n",
        "    if i == 0:\n",
        "        x = inputs\n",
        "\n",
        "    # CONV => RELU => BN => POOL\n",
        "    x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# flatten the volume, then FC => RELU => BN => DROPOUT\n",
        "x = Flatten()(x)\n",
        "x = Dense(16)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# apply another FC layer, this one to match the number of nodes\n",
        "# coming out of the MLP\n",
        "x = Dense(4)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "\n",
        "# construct the CNN\n",
        "cnn = Model(inputs, x)"
      ],
      "metadata": {
        "id": "gP_zZD5-7oxy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import concatenate\n",
        "# create the input to our final set of layers as the *output* of both\n",
        "# the MLP and CNN\n",
        "# both the mlp output and the cnn output has 4 neurons > concat > result = 8 neurons\n",
        "combinedInput = concatenate([mlp.output, cnn.output])\n",
        "\n",
        "# our final FC layer head will have two dense layers, the final one\n",
        "# being our regression head\n",
        "x = Dense(4, activation=\"relu\")(combinedInput)\n",
        "x = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "model = Model(inputs=[mlp.input, cnn.input], outputs=x)"
      ],
      "metadata": {
        "id": "GJEyR0qP7pVZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "opt = Adam(learning_rate=1e-3)\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    decay_rate = 1e-3 / 200\n",
        "    return lr * (1 / (1 + decay_rate * epoch))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
      ],
      "metadata": {
        "id": "UQVcGvcy8J1X"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit(\n",
        "    [trainAttrX, trainImagesX], trainY,\n",
        "    validation_data=([testAttrX, testImagesX], testY),\n",
        "    epochs=200, batch_size=8,\n",
        "    callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSV5-vye8Shl",
        "outputId": "79003a33-b436-42ed-a744-b33207c8c187"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 5s 14ms/step - loss: 593889.6250 - val_loss: 70.9414 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 202817.9062 - val_loss: 71.0143 - lr: 1.0000e-03\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 102240.3828 - val_loss: 71.5096 - lr: 9.9999e-04\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 33695.9062 - val_loss: 71.4615 - lr: 9.9997e-04\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 6906.2422 - val_loss: 71.0990 - lr: 9.9995e-04\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 67.0726 - val_loss: 71.4103 - lr: 9.9992e-04\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 66.9755 - val_loss: 71.1337 - lr: 9.9989e-04\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 66.8859 - val_loss: 71.0350 - lr: 9.9986e-04\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 66.9817 - val_loss: 70.9950 - lr: 9.9982e-04\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 67.1227 - val_loss: 71.1572 - lr: 9.9977e-04\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.1299 - val_loss: 71.8398 - lr: 9.9972e-04\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.4328 - val_loss: 71.2059 - lr: 9.9967e-04\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.6124 - val_loss: 71.0480 - lr: 9.9961e-04\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1438 - val_loss: 70.9091 - lr: 9.9955e-04\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2725 - val_loss: 71.5774 - lr: 9.9948e-04\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8424 - val_loss: 71.2058 - lr: 9.9940e-04\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1390 - val_loss: 71.0153 - lr: 9.9932e-04\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.7284 - val_loss: 71.3829 - lr: 9.9924e-04\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.4284 - val_loss: 70.9858 - lr: 9.9915e-04\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9566 - val_loss: 71.2388 - lr: 9.9905e-04\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1225 - val_loss: 71.3442 - lr: 9.9895e-04\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9912 - val_loss: 71.1449 - lr: 9.9885e-04\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9534 - val_loss: 71.3281 - lr: 9.9874e-04\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8936 - val_loss: 71.5605 - lr: 9.9862e-04\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8362 - val_loss: 71.2065 - lr: 9.9850e-04\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0012 - val_loss: 71.1272 - lr: 9.9838e-04\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0202 - val_loss: 71.0007 - lr: 9.9825e-04\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1820 - val_loss: 71.4928 - lr: 9.9811e-04\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.1988 - val_loss: 71.5484 - lr: 9.9797e-04\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.6015 - val_loss: 70.8943 - lr: 9.9783e-04\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1096 - val_loss: 71.7145 - lr: 9.9768e-04\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8580 - val_loss: 71.4084 - lr: 9.9752e-04\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.8544 - val_loss: 71.1028 - lr: 9.9736e-04\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.3376 - val_loss: 71.3457 - lr: 9.9720e-04\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0193 - val_loss: 70.8974 - lr: 9.9703e-04\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.8035 - val_loss: 71.6452 - lr: 9.9686e-04\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.2969 - val_loss: 71.8060 - lr: 9.9668e-04\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.1947 - val_loss: 71.3574 - lr: 9.9649e-04\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.7680 - val_loss: 71.0736 - lr: 9.9630e-04\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8406 - val_loss: 71.2761 - lr: 9.9611e-04\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2082 - val_loss: 71.4891 - lr: 9.9591e-04\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.4672 - val_loss: 70.9646 - lr: 9.9570e-04\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.5365 - val_loss: 71.1784 - lr: 9.9550e-04\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9575 - val_loss: 71.1659 - lr: 9.9528e-04\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 66.9458 - val_loss: 71.8182 - lr: 9.9506e-04\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 67.0370 - val_loss: 71.4005 - lr: 9.9484e-04\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 66.8179 - val_loss: 70.9305 - lr: 9.9461e-04\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 67.1781 - val_loss: 70.9393 - lr: 9.9438e-04\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 67.5065 - val_loss: 70.9246 - lr: 9.9414e-04\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 67.1234 - val_loss: 71.2101 - lr: 9.9389e-04\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1830 - val_loss: 71.3600 - lr: 9.9365e-04\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0432 - val_loss: 70.9391 - lr: 9.9339e-04\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8282 - val_loss: 71.3500 - lr: 9.9313e-04\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 67.1456 - val_loss: 70.9567 - lr: 9.9287e-04\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1265 - val_loss: 71.1115 - lr: 9.9260e-04\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1574 - val_loss: 71.1957 - lr: 9.9233e-04\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8230 - val_loss: 70.8967 - lr: 9.9205e-04\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.4245 - val_loss: 71.7405 - lr: 9.9177e-04\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9649 - val_loss: 71.4173 - lr: 9.9148e-04\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0005 - val_loss: 70.9283 - lr: 9.9119e-04\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9891 - val_loss: 71.3075 - lr: 9.9089e-04\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.8544 - val_loss: 71.2523 - lr: 9.9059e-04\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.1913 - val_loss: 71.2830 - lr: 9.9028e-04\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8207 - val_loss: 71.1088 - lr: 9.8997e-04\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.7583 - val_loss: 71.2697 - lr: 9.8966e-04\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.4376 - val_loss: 71.6138 - lr: 9.8933e-04\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9620 - val_loss: 70.9523 - lr: 9.8901e-04\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.2259 - val_loss: 71.1877 - lr: 9.8868e-04\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.1104 - val_loss: 71.3888 - lr: 9.8834e-04\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1088 - val_loss: 70.8961 - lr: 9.8800e-04\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.6813 - val_loss: 71.0296 - lr: 9.8765e-04\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.8339 - val_loss: 71.1432 - lr: 9.8730e-04\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.3859 - val_loss: 70.8948 - lr: 9.8695e-04\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1227 - val_loss: 71.2379 - lr: 9.8659e-04\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0827 - val_loss: 71.5006 - lr: 9.8622e-04\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 68.0254 - val_loss: 70.9208 - lr: 9.8585e-04\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1530 - val_loss: 71.2234 - lr: 9.8548e-04\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.3883 - val_loss: 71.9615 - lr: 9.8510e-04\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0594 - val_loss: 71.4178 - lr: 9.8471e-04\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8949 - val_loss: 71.4652 - lr: 9.8433e-04\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.7173 - val_loss: 70.9385 - lr: 9.8393e-04\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.4598 - val_loss: 71.1869 - lr: 9.8353e-04\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0829 - val_loss: 71.5542 - lr: 9.8313e-04\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 67.0211 - val_loss: 71.0899 - lr: 9.8272e-04\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 14ms/step - loss: 67.7371 - val_loss: 71.6435 - lr: 9.8231e-04\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 67.2823 - val_loss: 71.4343 - lr: 9.8189e-04\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 67.1634 - val_loss: 71.1635 - lr: 9.8147e-04\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 66.9349 - val_loss: 71.5207 - lr: 9.8104e-04\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 66.7941 - val_loss: 71.0376 - lr: 9.8061e-04\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2302 - val_loss: 71.6806 - lr: 9.8018e-04\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2901 - val_loss: 71.8042 - lr: 9.7974e-04\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.7590 - val_loss: 71.2166 - lr: 9.7929e-04\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0128 - val_loss: 71.5241 - lr: 9.7884e-04\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9806 - val_loss: 70.9565 - lr: 9.7839e-04\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.3874 - val_loss: 71.0320 - lr: 9.7793e-04\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0196 - val_loss: 71.7667 - lr: 9.7746e-04\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8201 - val_loss: 70.9346 - lr: 9.7699e-04\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2017 - val_loss: 71.1312 - lr: 9.7652e-04\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.6490 - val_loss: 70.9337 - lr: 9.7604e-04\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0459 - val_loss: 70.9817 - lr: 9.7556e-04\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9061 - val_loss: 71.1280 - lr: 9.7507e-04\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 66.8625 - val_loss: 71.5478 - lr: 9.7458e-04\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.6407 - val_loss: 71.0534 - lr: 9.7408e-04\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0468 - val_loss: 71.4829 - lr: 9.7358e-04\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9320 - val_loss: 71.1559 - lr: 9.7307e-04\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0125 - val_loss: 71.4780 - lr: 9.7256e-04\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 67.0242 - val_loss: 71.5064 - lr: 9.7205e-04\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.8001 - val_loss: 71.3037 - lr: 9.7153e-04\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.1553 - val_loss: 70.9281 - lr: 9.7100e-04\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8162 - val_loss: 71.5112 - lr: 9.7048e-04\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0165 - val_loss: 71.0349 - lr: 9.6994e-04\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0899 - val_loss: 70.9739 - lr: 9.6940e-04\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.7757 - val_loss: 71.3996 - lr: 9.6886e-04\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.7804 - val_loss: 70.9345 - lr: 9.6831e-04\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9137 - val_loss: 71.2894 - lr: 9.6776e-04\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9632 - val_loss: 71.3212 - lr: 9.6721e-04\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9654 - val_loss: 71.1857 - lr: 9.6665e-04\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1802 - val_loss: 71.0231 - lr: 9.6608e-04\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 67.3761 - val_loss: 71.7957 - lr: 9.6551e-04\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0634 - val_loss: 71.1266 - lr: 9.6494e-04\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1585 - val_loss: 71.5680 - lr: 9.6436e-04\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9032 - val_loss: 71.2232 - lr: 9.6377e-04\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 66.9778 - val_loss: 71.1945 - lr: 9.6319e-04\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 67.1784 - val_loss: 71.4377 - lr: 9.6260e-04\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 67.0867 - val_loss: 71.0156 - lr: 9.6200e-04\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 66.9310 - val_loss: 71.1000 - lr: 9.6140e-04\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 66.9230 - val_loss: 71.3853 - lr: 9.6079e-04\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 67.6842 - val_loss: 72.1171 - lr: 9.6018e-04\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.2540 - val_loss: 71.0861 - lr: 9.5957e-04\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 67.1775 - val_loss: 71.9695 - lr: 9.5895e-04\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.6300 - val_loss: 71.7672 - lr: 9.5833e-04\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9832 - val_loss: 71.0278 - lr: 9.5770e-04\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9821 - val_loss: 71.7158 - lr: 9.5707e-04\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0503 - val_loss: 71.3986 - lr: 9.5643e-04\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9706 - val_loss: 70.8945 - lr: 9.5579e-04\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2221 - val_loss: 71.2142 - lr: 9.5515e-04\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0433 - val_loss: 71.4618 - lr: 9.5450e-04\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8782 - val_loss: 71.7150 - lr: 9.5384e-04\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0670 - val_loss: 71.0697 - lr: 9.5319e-04\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9502 - val_loss: 71.5211 - lr: 9.5253e-04\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9384 - val_loss: 71.4241 - lr: 9.5186e-04\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8881 - val_loss: 71.2140 - lr: 9.5119e-04\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.7925 - val_loss: 71.2558 - lr: 9.5051e-04\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.8196 - val_loss: 71.4296 - lr: 9.4983e-04\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8253 - val_loss: 71.0728 - lr: 9.4915e-04\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.8922 - val_loss: 71.2321 - lr: 9.4846e-04\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0357 - val_loss: 71.4332 - lr: 9.4777e-04\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9202 - val_loss: 70.9288 - lr: 9.4708e-04\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0604 - val_loss: 70.9017 - lr: 9.4637e-04\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0452 - val_loss: 71.5420 - lr: 9.4567e-04\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2328 - val_loss: 70.9302 - lr: 9.4496e-04\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.5204 - val_loss: 71.1107 - lr: 9.4425e-04\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.3771 - val_loss: 71.2210 - lr: 9.4353e-04\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1272 - val_loss: 71.1796 - lr: 9.4281e-04\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0349 - val_loss: 71.6766 - lr: 9.4208e-04\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 67.0250 - val_loss: 71.1527 - lr: 9.4136e-04\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0658 - val_loss: 70.9145 - lr: 9.4062e-04\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.6929 - val_loss: 71.8323 - lr: 9.3988e-04\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9958 - val_loss: 71.0234 - lr: 9.3914e-04\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9691 - val_loss: 71.0315 - lr: 9.3840e-04\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2003 - val_loss: 71.1504 - lr: 9.3765e-04\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 66.9732 - val_loss: 71.0890 - lr: 9.3689e-04\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 66.9248 - val_loss: 71.1824 - lr: 9.3613e-04\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 66.9103 - val_loss: 71.6360 - lr: 9.3537e-04\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 67.8447 - val_loss: 71.7019 - lr: 9.3460e-04\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 67.0661 - val_loss: 71.6507 - lr: 9.3383e-04\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 67.1468 - val_loss: 71.3070 - lr: 9.3306e-04\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0472 - val_loss: 71.6774 - lr: 9.3228e-04\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9569 - val_loss: 70.9292 - lr: 9.3150e-04\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8990 - val_loss: 71.1161 - lr: 9.3071e-04\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8277 - val_loss: 71.2499 - lr: 9.2992e-04\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.7978 - val_loss: 71.2453 - lr: 9.2913e-04\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9808 - val_loss: 70.9357 - lr: 9.2833e-04\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.7648 - val_loss: 71.9029 - lr: 9.2753e-04\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9338 - val_loss: 71.1875 - lr: 9.2672e-04\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 66.9879 - val_loss: 70.9128 - lr: 9.2591e-04\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.2776 - val_loss: 71.3658 - lr: 9.2510e-04\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8819 - val_loss: 71.3734 - lr: 9.2428e-04\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0874 - val_loss: 70.9052 - lr: 9.2346e-04\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1850 - val_loss: 71.2184 - lr: 9.2263e-04\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0077 - val_loss: 71.3394 - lr: 9.2180e-04\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.8965 - val_loss: 71.2916 - lr: 9.2097e-04\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8355 - val_loss: 71.2780 - lr: 9.2013e-04\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1313 - val_loss: 71.3199 - lr: 9.1929e-04\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.7918 - val_loss: 71.6519 - lr: 9.1844e-04\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9492 - val_loss: 71.3397 - lr: 9.1760e-04\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.2928 - val_loss: 71.3407 - lr: 9.1674e-04\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.0312 - val_loss: 71.1016 - lr: 9.1589e-04\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8805 - val_loss: 71.9968 - lr: 9.1503e-04\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 67.1701 - val_loss: 71.5075 - lr: 9.1416e-04\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.8644 - val_loss: 71.0740 - lr: 9.1329e-04\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.7910 - val_loss: 71.1245 - lr: 9.1242e-04\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9952 - val_loss: 71.2148 - lr: 9.1155e-04\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9505 - val_loss: 71.2244 - lr: 9.1067e-04\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0793 - val_loss: 71.4376 - lr: 9.0979e-04\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 67.0333 - val_loss: 70.9317 - lr: 9.0890e-04\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 66.9365 - val_loss: 71.6210 - lr: 9.0801e-04\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.8601 - val_loss: 70.9555 - lr: 9.0712e-04\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.7788 - val_loss: 71.4250 - lr: 9.0622e-04\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 66.9382 - val_loss: 71.3858 - lr: 9.0532e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c828c568bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([testAttrX, testImagesX], testY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z47CK5-NLJn8",
        "outputId": "58cca51c-4a52-49dd-9d81-2f1a04eeeab3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 71.3858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.38579559326172"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on the testing data\n",
        "preds = model.predict([testAttrX, testImagesX])"
      ],
      "metadata": {
        "id": "Q6mJJ2r48WFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45317ec-d3c2-423e-f219-870d1dbe583e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the difference between the *predicted* house prices and the\n",
        "# *actual* house prices, then compute the percentage difference and\n",
        "# the absolute percentage difference\n",
        "diff = preds.flatten() - testY\n",
        "percentDiff = (diff / testY) * 100\n",
        "absPercentDiff = np.abs(percentDiff)\n",
        "\n",
        "# compute the mean and standard deviation of the absolute percentage\n",
        "# difference\n",
        "mean = np.mean(absPercentDiff)\n",
        "std = np.std(absPercentDiff)\n",
        "\n",
        "# finally, show some statistics on our model\n",
        "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
        "print(\"[INFO] avg. house price: {}, std house price: {}\".format(\n",
        "    locale.currency(df[\"price\"].mean(), grouping=True),\n",
        "    locale.currency(df[\"price\"].std(), grouping=True)))\n",
        "print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"
      ],
      "metadata": {
        "id": "r08C6jeK8k7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db42c3d7-69b7-419f-ba1d-84dae79aed38"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] avg. house price: $533,388.27, std house price: $493,403.08\n",
            "[INFO] mean: 71.39%, std: 22.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4Kj6yM4MODq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "nbpresent": {
      "slides": {
        "300ee14f-a043-486e-b274-7ff253907cd7": {
          "id": "300ee14f-a043-486e-b274-7ff253907cd7",
          "prev": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
          "regions": {
            "26dc3f39-a230-447c-af4c-f5e5b2fb7835": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "c58440a5-3f8f-4f37-9c79-6bf766209406",
                "part": "whole"
              },
              "id": "26dc3f39-a230-447c-af4c-f5e5b2fb7835"
            }
          }
        },
        "878aa53a-1444-4100-8f50-7a408191c579": {
          "id": "878aa53a-1444-4100-8f50-7a408191c579",
          "prev": null,
          "regions": {
            "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "588ee1fa-64b5-453b-ade7-8e6b2515821c",
                "part": "whole"
              },
              "id": "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3"
            }
          }
        },
        "96ffe88e-7b50-43de-afdd-942e564f4e3e": {
          "id": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
          "prev": "878aa53a-1444-4100-8f50-7a408191c579",
          "regions": {
            "b7e52e12-489a-468d-b10c-af2024fd2856": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "de829a92-1fb6-44ad-a2c6-fc1001e1f6e1",
                "part": "whole"
              },
              "id": "b7e52e12-489a-468d-b10c-af2024fd2856"
            }
          }
        },
        "cb74e0bc-4513-4d13-b7f1-14c3078a7927": {
          "id": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
          "prev": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
          "regions": {
            "444878ee-68f3-4abb-acff-a7079b21e86d": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "25f3f538-1ee8-4d98-a6bb-14cbeb7a702d",
                "part": "whole"
              },
              "id": "444878ee-68f3-4abb-acff-a7079b21e86d"
            }
          }
        }
      },
      "themes": {}
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}